{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "512447ed-ca6f-4d09-bf72-ab84587f7798",
   "metadata": {},
   "source": [
    "# ◇ 라이브러리 설정 MNIST, numpy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "id": "703a29df-fcf6-41e2-a7f6-8f9123a1d087",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import sys, os\n",
    "sys.path.append(os.pardir)\n",
    "import numpy as np\n",
    "from dataset.mnist import load_mnist\n",
    "from collections import OrderedDict"
   ]
  },
  {
   "attachments": {
    "8d7f22dd-1fe5-4f25-9a13-ed54f875196f.png": {
     "image/png": "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"
    }
   },
   "cell_type": "markdown",
   "id": "f203ffeb-9f3c-4afb-99c2-ff7548439c2f",
   "metadata": {},
   "source": [
    "# ◇ 계층 클래스 Affine\n",
    "#### Affine클래스는 해당 부분을 저장\n",
    "![image.png](attachment:8d7f22dd-1fe5-4f25-9a13-ed54f875196f.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "id": "416b1d0a-13ea-44e5-9bdc-a7dbcbae826b",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Affine:\n",
    "    def __init__(self, W, b):\n",
    "        self.W = W\n",
    "        self.b = b\n",
    "        \n",
    "        self.x = None\n",
    "        self.original_x_shape = None\n",
    "        # 가중치와 편향 매개변수의 미분\n",
    "        self.dW = None\n",
    "        self.db = None\n",
    "\n",
    "    def forward(self, x, flg):\n",
    "        # 텐서 대응\n",
    "        self.original_x_shape = x.shape\n",
    "        x = x.reshape(x.shape[0], -1)\n",
    "        self.x = x\n",
    "\n",
    "        #print(self.x.shape, self.W.shape)\n",
    "        out = np.dot(self.x, self.W) + self.b\n",
    "\n",
    "        return out\n",
    "\n",
    "    def backward(self, dout):\n",
    "        dx = np.dot(dout, self.W.T)\n",
    "        self.dW = np.dot(self.x.T, dout)\n",
    "        self.db = np.sum(dout, axis=0)\n",
    "        \n",
    "        dx = dx.reshape(*self.original_x_shape)  # 입력 데이터 모양 변경(텐서 대응)\n",
    "        return dx"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0f833bc6-a684-4aae-bfe6-1dc5eb1deea7",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "# ◇ 활성화 함수 Relu, softmax\n",
    "# ◇ 손실 함수 cross_entropy_error (교차 엔트로피 오차)\n",
    "# ◇ 수치미분-기울기 numerical_gradient\n",
    "# ◇ 출력층 클래스 -> 소프트맥스, 손실 함수 값을 계산-저장 SoftmaxWithLoss"
   ]
  },
  {
   "attachments": {
    "bd1cf732-a572-423f-b55b-73b2ffe87b4d.png": {
     "image/png": "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"
    }
   },
   "cell_type": "markdown",
   "id": "5b826560-ed44-4924-a0b6-505c35fdb261",
   "metadata": {},
   "source": [
    "----\n",
    "#### class Relu는 해당 부분을 저장\n",
    "![image.png](attachment:bd1cf732-a572-423f-b55b-73b2ffe87b4d.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "id": "900abb2e-bfb9-445b-a126-c27b6a04fc56",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Relu 활성화 함수 순전파, 역전파를 저장하는 클래스\n",
    "class Relu:\n",
    "    def __init__(self):\n",
    "        self.mask = None\n",
    "\n",
    "    def forward(self, x, flg):\n",
    "        self.mask = (x <= 0)\n",
    "        out = x.copy()\n",
    "        out[self.mask] = 0\n",
    "\n",
    "        return out\n",
    "\n",
    "    def backward(self, dout):\n",
    "        dout[self.mask] = 0\n",
    "        dx = dout\n",
    "\n",
    "        return dx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "id": "0269eb61-553f-439e-a374-83fc8f58d409",
   "metadata": {},
   "outputs": [],
   "source": [
    "def softmax(x):\n",
    "    if x.ndim == 2:\n",
    "        x = x.T\n",
    "        x = x - np.max(x, axis=0)\n",
    "        y = np.exp(x) / np.sum(np.exp(x), axis=0)\n",
    "        return y.T \n",
    "\n",
    "    x = x - np.max(x) # 오버플로 대책\n",
    "    return np.exp(x) / np.sum(np.exp(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "id": "b7b8e697-02c5-4dfe-b1ae-58b68d3a9c41",
   "metadata": {},
   "outputs": [],
   "source": [
    "def cross_entropy_error(y, t):\n",
    "    if y.ndim == 1:\n",
    "        t = t.reshape(1, t.size)\n",
    "        y = y.reshape(1, y.size)\n",
    "        \n",
    "    if t.size == y.size:\n",
    "        t = t.argmax(axis=1)\n",
    "             \n",
    "    batch_size = y.shape[0]\n",
    "    return -np.sum(np.log(y[np.arange(batch_size), t] + 1e-7)) / batch_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "id": "03e460e1-bfc6-4a06-818b-02c9051cf088",
   "metadata": {},
   "outputs": [],
   "source": [
    "def numerical_gradient(f, x):\n",
    "    h = 1e-4 # 0.0001\n",
    "    grad = np.zeros_like(x)\n",
    "    \n",
    "    it = np.nditer(x, flags=['multi_index'], op_flags=['readwrite'])\n",
    "    while not it.finished:\n",
    "        idx = it.multi_index\n",
    "        tmp_val = x[idx]\n",
    "        x[idx] = float(tmp_val) + h\n",
    "        fxh1 = f(x) # f(x+h)\n",
    "        \n",
    "        x[idx] = tmp_val - h \n",
    "        fxh2 = f(x) # f(x-h)\n",
    "        grad[idx] = (fxh1 - fxh2) / (2*h)\n",
    "        \n",
    "        x[idx] = tmp_val # 값 복원\n",
    "        it.iternext()   \n",
    "        \n",
    "    return grad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "id": "161c7d2d-c4cc-4ce3-89c3-5ceac9417267",
   "metadata": {},
   "outputs": [],
   "source": [
    "class SoftmaxWithLoss:\n",
    "    def __init__(self):\n",
    "        self.loss = None # 손실함수\n",
    "        self.y = None    # softmax의 출력\n",
    "        self.t = None    # 정답 레이블(원-핫 인코딩 형태)\n",
    "        \n",
    "    def forward(self, x, t):\n",
    "        self.t = t\n",
    "        self.y = softmax(x)\n",
    "        self.loss = cross_entropy_error(self.y, self.t)\n",
    "        \n",
    "        return self.loss\n",
    "\n",
    "    def backward(self, dout=1):\n",
    "        batch_size = self.t.shape[0]\n",
    "        if self.t.size == self.y.size: # 정답 레이블이 원-핫 인코딩 형태일 때\n",
    "            dx = (self.y - self.t) / batch_size\n",
    "        else:\n",
    "            dx = self.y.copy()\n",
    "            dx[np.arange(batch_size), self.t] -= 1\n",
    "            dx = dx / batch_size\n",
    "        \n",
    "        return dx"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2537370a-1915-42f0-9c91-f5cc11998fc8",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "# ◇ 최적화 함수 SGD, Momentum, AdaGrad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "id": "30cb3c94-71ab-480f-ad5c-911166b74ffc",
   "metadata": {},
   "outputs": [],
   "source": [
    "class SGD:\n",
    "    def __init__(self, Ir=0.01):\n",
    "        self.Ir =Ir\n",
    "\n",
    "    def update(self, params, grads):\n",
    "        for key in params.keys():\n",
    "            params[key] -= self.Ir * grads[key]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "id": "0f0c4a9c-4131-4946-962d-154d22eddf8b",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Momentum:\n",
    "    def __init__(self, lr=0.01, momentum=0.9):\n",
    "        self.lr = lr\n",
    "        self.momentum = momentum\n",
    "        self.v = None\n",
    "\n",
    "    def update(self, params, grads):\n",
    "        if self.v is None:\n",
    "            self.v = {}\n",
    "            for key, val in params.items():\n",
    "                self.v[key] = np.zeros_like(val)\n",
    "\n",
    "        for key in params.keys():\n",
    "            self.v[key] = self.momentum * self.v[key] - self.lr * grads[key]\n",
    "            params[key] += self.v[key]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "id": "df7ccc05-fa98-4a9a-8e0a-adf50ac4d2d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "class AdaGrad:\n",
    "    def __init__ (self, Ir=0.01):\n",
    "        self.Ir =Ir\n",
    "        self.h = None\n",
    "        \n",
    "    def update(self, params, grads):\n",
    "        if self.h is None:\n",
    "            self.h = {}\n",
    "            for key, val in params.items():\n",
    "                self.h[key] = np.zeros_like(val)\n",
    "\n",
    "        for key in params.keys() :\n",
    "            self.h[key] += grads[key] * grads[key]\n",
    "            params[key] -= self.Ir * grads[key] / (np.sqrt(self.h[key]) + 1e-7)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "705ad2f6-185b-4724-a432-2e4638118105",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "# ◇ 학습 자료에 있는 배치 정규화 코드"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "id": "e592201f-c9dc-49a6-a6d9-3f52dad159bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "class BatchNormalization:\n",
    "    \"\"\"\n",
    "    http://arxiv.org/abs/1502.03167\n",
    "    \"\"\"\n",
    "    def __init__(self, gamma=1, beta=0, momentum=0.9, running_mean=None, running_var=None):\n",
    "        self.gamma = gamma\n",
    "        self.beta = beta\n",
    "        self.momentum = momentum\n",
    "        self.input_shape = None # 합성곱 계층은 4차원, 완전연결 계층은 2차원  \n",
    "\n",
    "        # 시험할 때 사용할 평균과 분산\n",
    "        self.running_mean = running_mean\n",
    "        self.running_var = running_var  \n",
    "        \n",
    "        # backward 시에 사용할 중간 데이터\n",
    "        self.batch_size = None\n",
    "        self.xc = None\n",
    "        self.std = None\n",
    "        self.dgamma = None\n",
    "        self.dbeta = None\n",
    "\n",
    "    def forward(self, x, train_flg=True):\n",
    "        self.input_shape = x.shape\n",
    "        if x.ndim != 2:\n",
    "            N, C, H, W = x.shape\n",
    "            x = x.reshape(N, -1)\n",
    "\n",
    "        out = self.__forward(x, train_flg)\n",
    "        \n",
    "        return out.reshape(*self.input_shape)\n",
    "            \n",
    "    def __forward(self, x, train_flg):\n",
    "        if self.running_mean is None:\n",
    "            N, D = x.shape\n",
    "            self.running_mean = np.zeros(D)\n",
    "            self.running_var = np.zeros(D)\n",
    "                        \n",
    "        if train_flg:\n",
    "            mu = x.mean(axis=0)\n",
    "            xc = x - mu\n",
    "            var = np.mean(xc**2, axis=0)\n",
    "            std = np.sqrt(var + 10e-7)\n",
    "            xn = xc / std\n",
    "            \n",
    "            self.batch_size = x.shape[0]\n",
    "            self.xc = xc\n",
    "            self.xn = xn\n",
    "            self.std = std\n",
    "            self.running_mean = self.momentum * self.running_mean + (1-self.momentum) * mu\n",
    "            self.running_var = self.momentum * self.running_var + (1-self.momentum) * var            \n",
    "        else:\n",
    "            xc = x - self.running_mean\n",
    "            xn = xc / ((np.sqrt(self.running_var + 10e-7)))\n",
    "            \n",
    "        out = self.gamma * xn + self.beta \n",
    "        return out\n",
    "\n",
    "    def backward(self, dout):\n",
    "        if dout.ndim != 2:\n",
    "            N, C, H, W = dout.shape\n",
    "            dout = dout.reshape(N, -1)\n",
    "\n",
    "        dx = self.__backward(dout)\n",
    "\n",
    "        dx = dx.reshape(*self.input_shape)\n",
    "        return dx\n",
    "\n",
    "    def __backward(self, dout):\n",
    "        dbeta = dout.sum(axis=0)\n",
    "        dgamma = np.sum(self.xn * dout, axis=0)\n",
    "        dxn = self.gamma * dout\n",
    "        dxc = dxn / self.std\n",
    "        dstd = -np.sum((dxn * self.xc) / (self.std * self.std), axis=0)\n",
    "        dvar = 0.5 * dstd / self.std\n",
    "        dxc += (2.0 / self.batch_size) * self.xc * dvar\n",
    "        dmu = np.sum(dxc, axis=0)\n",
    "        dx = dxc - dmu / self.batch_size\n",
    "        \n",
    "        self.dgamma = dgamma\n",
    "        self.dbeta = dbeta\n",
    "        \n",
    "        return dx"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e8d61b57-e961-4aba-907a-a7363c23a617",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "# ◇ 가중치 초기화 He"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "id": "6e97a344-d757-4dfd-8c54-74d3316db214",
   "metadata": {},
   "outputs": [],
   "source": [
    "def He_init(input, ouput):\n",
    "    return np.sqrt(2.0 / input) * np.random.randn(input, ouput)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ebca134e-acc5-4564-8087-4359506948b9",
   "metadata": {},
   "source": [
    "# ◇ 다층 신경망 클래스"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "id": "efbc06eb-3fe1-40fb-9bde-7398eda3a619",
   "metadata": {},
   "outputs": [],
   "source": [
    "class TwoLayerNet:\n",
    "\n",
    "    def __init__(self, input_size, hidden_size, output_size, weight_init_std = 0.01):\n",
    "        # 가중치 초기화\n",
    "        self.maxIndex = len(hidden_size)\n",
    "        print(\"\\n\\n신경망 학습 시작 - 신경망: %d층\"%(self.maxIndex+1))\n",
    "        \n",
    "        self.params = {}        \n",
    "        self.params['W1'] = He_init(input_size, hidden_size[0])\n",
    "        self.params['b1'] = np.zeros(hidden_size[0])\n",
    "\n",
    "        #print(self.params['W1'].shape)\n",
    "\n",
    "        for i in range(1, self.maxIndex):\n",
    "            self.params['W' + str(i+1)] = He_init(hidden_size[i-1], hidden_size[i]) \n",
    "            self.params['b' + str(i+1)] = np.zeros(hidden_size[i])\n",
    "            #print(self.params['W'  + str(i+1)].shape)\n",
    "\n",
    "        self.params['W' + str(self.maxIndex)] = He_init(hidden_size[self.maxIndex - 1], output_size) \n",
    "        self.params['b' + str(self.maxIndex)] = np.zeros(output_size)\n",
    "        #print(self.params['W' + str(self.maxIndex)].shape)\n",
    "\n",
    "        # 계층 생성\n",
    "        self.layers = OrderedDict()\n",
    "        \n",
    "        for i in range(1, self.maxIndex):\n",
    "            self.layers['Affine' + str(i)] = Affine(self.params['W' + str(i)], self.params['b' + str(i)])\n",
    "            self.layers['BatchNormalization' + str(i)] = BatchNormalization()\n",
    "            self.layers['Relu' + str(i)] = Relu()\n",
    "    \n",
    "        self.layers['Affine' + str(self.maxIndex)] = Affine(self.params['W' + str(self.maxIndex)], self.params['b' + str(self.maxIndex)])\n",
    "\n",
    "        self.lastLayer = SoftmaxWithLoss()\n",
    "        \n",
    "    def predict(self, x, train_flg=True):\n",
    "        for layer in self.layers.values():\n",
    "            x = layer.forward(x, train_flg)\n",
    "        return x\n",
    "        \n",
    "    def loss(self, x, t):\n",
    "        y = self.predict(x)\n",
    "        return self.lastLayer.forward(y, t)\n",
    "    \n",
    "    def accuracy(self, x, t):\n",
    "        y = self.predict(x, False)\n",
    "        y = np.argmax(y, axis=1)\n",
    "        if t.ndim != 1 : t = np.argmax(t, axis=1)\n",
    "        accuracy = np.sum(y == t) / float(x.shape[0])\n",
    "        return accuracy\n",
    "        \n",
    "    # x : 입력 데이터, t : 정답 레이블\n",
    "    def numerical_gradient(self, x, t):\n",
    "        loss_W = lambda W: self.loss(x, t)\n",
    "        \n",
    "        grads = {}\n",
    "\n",
    "        for i in range(1, self.maxIndex+1):\n",
    "            grads['W' + str(i)] = numerical_gradient(loss_W, self.params['W' + str(i)])\n",
    "            grads['b' + str(i)] = numerical_gradient(loss_W, self.params['b' + str(i)])\n",
    "\n",
    "        return grads\n",
    "        \n",
    "    def gradient(self, x, t):\n",
    "        # forward\n",
    "        self.loss(x, t)\n",
    "\n",
    "        # 역전파\n",
    "        dout = 1\n",
    "        dout = self.lastLayer.backward(dout)\n",
    "\n",
    "        # 계층 레이어의 값을 리스트로 변환하여 가져옴 -> 해당 리스트를 거꾸로 정렬 -> 순서대로 계층의 역전파를 실행\n",
    "        layers = list(self.layers.values())\n",
    "        layers.reverse()\n",
    "        for layer in layers:\n",
    "            dout = layer.backward(dout)\n",
    "\n",
    "        # 기울기\n",
    "        grads = {}\n",
    "        for i in range(1, self.maxIndex+1):\n",
    "            grads['W' + str(i)], grads['b' + str(i)] = self.layers['Affine' + str(i)].dW, self.layers['Affine' + str(i)].db\n",
    "        \n",
    "        return grads\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fe045263-ea41-4b2d-9b4e-e6355b8731bf",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "# ◇ MNIST 불러오기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "id": "bac8b5d5-172c-4d85-b11a-47e141c19710",
   "metadata": {},
   "outputs": [],
   "source": [
    "(x_train, t_train), (x_test, t_test) = load_mnist(normalize=True, one_hot_label=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c2faaf13-6d43-40cc-aad4-118070e02d56",
   "metadata": {},
   "source": [
    "----\n",
    "# 과제) 신경망 학습 코드 작성 시 발생한 문제와 해결 내용\n",
    "<br/>\n",
    "\n",
    "### 1) 기존 가중치 업데이트 방식 가중치 - (학습률*기울기) / 해당 방법으로 업데이트 시 학습이 잘 안됨\n",
    "#### &emsp;&emsp;&emsp;--> 해결방법 : SGD, 모멘텀, AdaGrad를 사용해서 적절한 기울기 업데이트 방법을 사용하니 학습이 잘되는 것을 확인\n",
    "<br/>\n",
    "\n",
    "### 2) 2층 신경망에서는 학습에 문제가 없었으나 4층으로 늘릴 시 학습이 안되는 문제가 발생\n",
    "#### &emsp;&emsp;&emsp;--> 해결방법 : 초기화 방법을 변경 / ReLu함수의 가중치 초기화를  He초기화(He_init 함수)로 하니 정상적으로 학습이 가능함\n",
    "#### &emsp;&emsp;&emsp;&emsp;&emsp; 이후 층을 늘려도 학습이 되는 것을 확인\n",
    "<br/>\n",
    "\n",
    "### 3) 초기값, 모멘텀, SGD 등을 통해 어느정도 학습은 가능하나 일정 수준 이상으로 학습이 되지 않음\n",
    "#### &emsp;&emsp;&emsp;--> 해결방법 : 교제에 나온 배치치 정규화를 시도\n",
    "<br/>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b34859dd-c506-48e6-aea8-c0e96a414333",
   "metadata": {},
   "source": [
    "\n",
    "# ◇ 학습 알고리즘 \n",
    "<br />\n",
    "\n",
    "## 계산 과정\n",
    "1. TwoLayerNet클래스로 가중치 초기화 밑 신경망 구조를 설정 (hidden_size을 리스트로 보내어 좀 더 간단하게 층과 노드를 설정)\n",
    "2. 횟수는 1만번 진행하며, 하이퍼피라미터를 수정\n",
    "3. 배치 사이즈만큼 학습, 시험 데이터를 TwoLayerNet.gradient 으로 보내어 기울기를 구한다\n",
    "- - 1. loss함수에서 predict함수를 호출하여 순전파를 진행한다 (OrderedDict으로 순서가 있는 딕셔너리를 통해 입력층부터 계산)\n",
    "    2. predict함수는 출력층 전까지 값을 리턴한 후 loss함수에서 SoftmaxWithLoss클래스에 소프트맥스값, 교차 엔트로피 오차(손실)값을 설정한다.\n",
    "    3. 2번에서 설정한 SoftmaxWithLoss클래스를 역전파를 하고, OrderedDict를 리스트로 변환하여 거꾸로 정렬, 순서대로 Affine, ReLu클래스의 역전파를 실행\n",
    "    4. 역전파를 통해 각 Affine클래스에 저장된 dw, db값을 grads에 저장한 후 리턴\n",
    "4. 구한 기울기를 SGD, Momentum, AdaGrad 중 1개를 이용하여 기존 기울기에 업데이트를 진행\n",
    "\n",
    "## 하이퍼피라미터\n",
    "- #### iters_num : 반복 횟수 = **10,000 고정**\n",
    "- #### batch_size : 배치 사이즈 = **100~300?**\n",
    "- #### hidden_size : 은닉층 노드 수 = **5 ~ 15**\n",
    "- #### learning_rate : 학습률 = **0.001 ~ 0.019**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "id": "a4eb85f2-7534-48d2-a079-75bf36710c6d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "신경망 학습 시작 - 신경망: 4층\n",
      " 1 번째 학습(에폭) --> train_acc : 9.79%, test_acc : 9.89%\n",
      " 2 번째 학습(에폭) --> train_acc : 91.30%, test_acc : 91.73%\n",
      " 3 번째 학습(에폭) --> train_acc : 92.83%, test_acc : 92.65%\n",
      " 4 번째 학습(에폭) --> train_acc : 93.78%, test_acc : 93.62%\n",
      " 5 번째 학습(에폭) --> train_acc : 94.40%, test_acc : 93.77%\n",
      " 6 번째 학습(에폭) --> train_acc : 94.95%, test_acc : 94.61%\n",
      " 7 번째 학습(에폭) --> train_acc : 94.95%, test_acc : 94.21%\n",
      " 8 번째 학습(에폭) --> train_acc : 95.46%, test_acc : 94.67%\n",
      " 9 번째 학습(에폭) --> train_acc : 95.64%, test_acc : 95.02%\n",
      "10 번째 학습(에폭) --> train_acc : 95.82%, test_acc : 94.93%\n",
      "11 번째 학습(에폭) --> train_acc : 95.84%, test_acc : 95.05%\n",
      "12 번째 학습(에폭) --> train_acc : 96.03%, test_acc : 95.08%\n",
      "13 번째 학습(에폭) --> train_acc : 96.15%, test_acc : 95.24%\n",
      "14 번째 학습(에폭) --> train_acc : 96.27%, test_acc : 95.30%\n",
      "15 번째 학습(에폭) --> train_acc : 96.32%, test_acc : 95.36%\n",
      "16 번째 학습(에폭) --> train_acc : 96.48%, test_acc : 95.22%\n",
      "17 번째 학습(에폭) --> train_acc : 96.59%, test_acc : 95.55%\n"
     ]
    }
   ],
   "source": [
    "iters_num = 10000\n",
    "batch_size = 100\n",
    "#hidden_size = 15 \n",
    "hidden_size = [15, 15, 15]\n",
    "learning_rate = 0.011\n",
    "\n",
    "# 기울기 최적화 함수들\n",
    "sgd = SGD()\n",
    "momentum = Momentum()\n",
    "adaGrad = AdaGrad()\n",
    "\n",
    "train_loss_list = []\n",
    "train_acc_list = []\n",
    "test_acc_list = []\n",
    "\n",
    "train_size = x_train.shape[0]\n",
    "iter_per_epoch = max(train_size / batch_size, 1)\n",
    "\n",
    "network = TwoLayerNet(input_size=784, hidden_size=hidden_size, output_size=10)\n",
    "\n",
    "for i in range(iters_num):\n",
    "    batch_mask = np.random.choice(train_size, batch_size)\n",
    "    x_batch = x_train[batch_mask]\n",
    "    t_batch = t_train[batch_mask]\n",
    "\n",
    "    grad = network.gradient(x_batch, t_batch) # 오차역전파법 방식\n",
    "    \n",
    "    # 일반 갱신\n",
    "    #for key in ('W1', 'b1', 'W2', 'b2'): network.params[key] -= learning_rate * grad[key]\n",
    "        \n",
    "    # SGD 학습, 모멘텀 학습, AdaGrad 학습\n",
    "    #sgd.update(network.params, grad)\n",
    "    momentum.update(network.params, grad)\n",
    "    #adaGrad.update(network.params, grad)\n",
    "    \n",
    "    \n",
    "    loss = network.loss(x_batch, t_batch)\n",
    "    train_loss_list.append(loss)\n",
    "    \n",
    "    if i % iter_per_epoch == 0:\n",
    "        train_acc = network.accuracy(x_train, t_train)\n",
    "        test_acc = network.accuracy(x_test, t_test)\n",
    "        train_acc_list.append(train_acc)\n",
    "        test_acc_list.append(test_acc)\n",
    "        print(\"%2d 번째 학습(에폭) --> train_acc : %.2f%%, test_acc : %.2f%%\" % (len(train_acc_list), train_acc*100, test_acc*100))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0f70fef2-d5d5-4457-93bc-9025cb52b372",
   "metadata": {},
   "source": [
    "----"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "id": "f0b8f9d4-e24e-49cb-ae62-c4bc3c82de3e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-05-11 18:45:25,252] A new study created in memory with name: no-name-5745871f-e9b3-4ff0-bc1c-972a7d120bf5\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "신경망 학습 시작 - 신경망: 5층\n",
      "learning_rate: 0.006426299155908802\n",
      "hidden_size: [15, 15, 15, 15]\n",
      "batch_size: 277\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-05-11 18:46:09,888] Trial 0 finished with value: 0.9492 and parameters: {'learning_rate': 0.006426299155908802, 'num_layers': 4, 'iters_num': 10000, 'batch_size': 277}. Best is trial 0 with value: 0.9492.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(에폭) --> train_acc : 96.37%, test_acc : 94.92%\n",
      "\n",
      "\n",
      "신경망 학습 시작 - 신경망: 4층\n",
      "learning_rate: 0.004678349045190709\n",
      "hidden_size: [15, 15, 15]\n",
      "batch_size: 106\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-05-11 18:46:21,411] Trial 1 finished with value: 0.9427 and parameters: {'learning_rate': 0.004678349045190709, 'num_layers': 3, 'iters_num': 10000, 'batch_size': 106}. Best is trial 0 with value: 0.9492.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(에폭) --> train_acc : 94.96%, test_acc : 94.27%\n",
      "\n",
      "\n",
      "신경망 학습 시작 - 신경망: 6층\n",
      "learning_rate: 0.0053588095064247615\n",
      "hidden_size: [15, 15, 15, 15, 15]\n",
      "batch_size: 174\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-05-11 18:46:53,568] Trial 2 finished with value: 0.9499 and parameters: {'learning_rate': 0.0053588095064247615, 'num_layers': 5, 'iters_num': 10000, 'batch_size': 174}. Best is trial 2 with value: 0.9499.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(에폭) --> train_acc : 96.07%, test_acc : 94.99%\n",
      "\n",
      "\n",
      "신경망 학습 시작 - 신경망: 5층\n",
      "learning_rate: 0.016990431271023645\n",
      "hidden_size: [15, 15, 15, 15]\n",
      "batch_size: 124\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-05-11 18:47:08,880] Trial 3 finished with value: 0.9437 and parameters: {'learning_rate': 0.016990431271023645, 'num_layers': 4, 'iters_num': 10000, 'batch_size': 124}. Best is trial 2 with value: 0.9499.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(에폭) --> train_acc : 95.41%, test_acc : 94.37%\n",
      "\n",
      "\n",
      "신경망 학습 시작 - 신경망: 5층\n",
      "learning_rate: 0.012043323985586454\n",
      "hidden_size: [15, 15, 15, 15]\n",
      "batch_size: 203\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-05-11 18:47:41,989] Trial 4 finished with value: 0.9465 and parameters: {'learning_rate': 0.012043323985586454, 'num_layers': 4, 'iters_num': 10000, 'batch_size': 203}. Best is trial 2 with value: 0.9499.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(에폭) --> train_acc : 95.74%, test_acc : 94.65%\n",
      "\n",
      "\n",
      "신경망 학습 시작 - 신경망: 6층\n",
      "learning_rate: 0.008318704223403\n",
      "hidden_size: [15, 15, 15, 15, 15]\n",
      "batch_size: 267\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-05-11 18:48:27,209] Trial 5 finished with value: 0.9493 and parameters: {'learning_rate': 0.008318704223403, 'num_layers': 5, 'iters_num': 10000, 'batch_size': 267}. Best is trial 2 with value: 0.9499.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(에폭) --> train_acc : 96.61%, test_acc : 94.93%\n",
      "\n",
      "\n",
      "신경망 학습 시작 - 신경망: 7층\n",
      "learning_rate: 0.004740137950098687\n",
      "hidden_size: [15, 15, 15, 15, 15, 15]\n",
      "batch_size: 110\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-05-11 18:48:46,207] Trial 6 finished with value: 0.9509 and parameters: {'learning_rate': 0.004740137950098687, 'num_layers': 6, 'iters_num': 10000, 'batch_size': 110}. Best is trial 6 with value: 0.9509.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(에폭) --> train_acc : 96.01%, test_acc : 95.09%\n",
      "\n",
      "\n",
      "신경망 학습 시작 - 신경망: 5층\n",
      "learning_rate: 0.01700453235937839\n",
      "hidden_size: [15, 15, 15, 15]\n",
      "batch_size: 268\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-05-11 18:49:27,536] Trial 7 finished with value: 0.9508 and parameters: {'learning_rate': 0.01700453235937839, 'num_layers': 4, 'iters_num': 10000, 'batch_size': 268}. Best is trial 6 with value: 0.9509.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(에폭) --> train_acc : 96.51%, test_acc : 95.08%\n",
      "\n",
      "\n",
      "신경망 학습 시작 - 신경망: 7층\n",
      "learning_rate: 0.017854568692969662\n",
      "hidden_size: [15, 15, 15, 15, 15, 15]\n",
      "batch_size: 173\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-05-11 18:50:02,311] Trial 8 finished with value: 0.9445 and parameters: {'learning_rate': 0.017854568692969662, 'num_layers': 6, 'iters_num': 10000, 'batch_size': 173}. Best is trial 6 with value: 0.9509.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(에폭) --> train_acc : 95.72%, test_acc : 94.45%\n",
      "\n",
      "\n",
      "신경망 학습 시작 - 신경망: 7층\n",
      "learning_rate: 0.0011849390352265835\n",
      "hidden_size: [15, 15, 15, 15, 15, 15]\n",
      "batch_size: 192\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-05-11 18:50:40,288] Trial 9 finished with value: 0.9406 and parameters: {'learning_rate': 0.0011849390352265835, 'num_layers': 6, 'iters_num': 10000, 'batch_size': 192}. Best is trial 6 with value: 0.9509.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(에폭) --> train_acc : 95.72%, test_acc : 94.06%\n",
      "\n",
      "\n",
      "신경망 학습 시작 - 신경망: 7층\n",
      "learning_rate: 0.012383247945440257\n",
      "hidden_size: [15, 15, 15, 15, 15, 15]\n",
      "batch_size: 141\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-05-11 18:51:02,735] Trial 10 finished with value: 0.9456 and parameters: {'learning_rate': 0.012383247945440257, 'num_layers': 6, 'iters_num': 10000, 'batch_size': 141}. Best is trial 6 with value: 0.9509.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(에폭) --> train_acc : 95.60%, test_acc : 94.56%\n",
      "\n",
      "\n",
      "신경망 학습 시작 - 신경망: 4층\n",
      "learning_rate: 0.01457998574914637\n",
      "hidden_size: [15, 15, 15]\n",
      "batch_size: 233\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-05-11 18:51:36,128] Trial 11 finished with value: 0.9487 and parameters: {'learning_rate': 0.01457998574914637, 'num_layers': 3, 'iters_num': 10000, 'batch_size': 233}. Best is trial 6 with value: 0.9509.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(에폭) --> train_acc : 96.08%, test_acc : 94.87%\n",
      "\n",
      "\n",
      "신경망 학습 시작 - 신경망: 6층\n",
      "learning_rate: 0.002305237760082907\n",
      "hidden_size: [15, 15, 15, 15, 15]\n",
      "batch_size: 252\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-05-11 18:52:19,268] Trial 12 finished with value: 0.9439 and parameters: {'learning_rate': 0.002305237760082907, 'num_layers': 5, 'iters_num': 10000, 'batch_size': 252}. Best is trial 6 with value: 0.9509.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(에폭) --> train_acc : 96.31%, test_acc : 94.39%\n",
      "\n",
      "\n",
      "신경망 학습 시작 - 신경망: 5층\n",
      "learning_rate: 0.009115545487618934\n",
      "hidden_size: [15, 15, 15, 15]\n",
      "batch_size: 224\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-05-11 18:52:54,964] Trial 13 finished with value: 0.9477 and parameters: {'learning_rate': 0.009115545487618934, 'num_layers': 4, 'iters_num': 10000, 'batch_size': 224}. Best is trial 6 with value: 0.9509.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(에폭) --> train_acc : 96.08%, test_acc : 94.77%\n",
      "\n",
      "\n",
      "신경망 학습 시작 - 신경망: 6층\n",
      "learning_rate: 0.01509272761914134\n",
      "hidden_size: [15, 15, 15, 15, 15]\n",
      "batch_size: 287\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-05-11 18:53:43,268] Trial 14 finished with value: 0.9527 and parameters: {'learning_rate': 0.01509272761914134, 'num_layers': 5, 'iters_num': 10000, 'batch_size': 287}. Best is trial 14 with value: 0.9527.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(에폭) --> train_acc : 97.02%, test_acc : 95.27%\n",
      "\n",
      "\n",
      "신경망 학습 시작 - 신경망: 7층\n",
      "learning_rate: 0.011970890329398926\n",
      "hidden_size: [15, 15, 15, 15, 15, 15]\n",
      "batch_size: 300\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-05-11 18:54:37,451] Trial 15 finished with value: 0.9443 and parameters: {'learning_rate': 0.011970890329398926, 'num_layers': 6, 'iters_num': 10000, 'batch_size': 300}. Best is trial 14 with value: 0.9527.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(에폭) --> train_acc : 96.55%, test_acc : 94.43%\n",
      "\n",
      "\n",
      "신경망 학습 시작 - 신경망: 6층\n",
      "learning_rate: 0.014885741207569804\n",
      "hidden_size: [15, 15, 15, 15, 15]\n",
      "batch_size: 149\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-05-11 18:54:57,902] Trial 16 finished with value: 0.9467 and parameters: {'learning_rate': 0.014885741207569804, 'num_layers': 5, 'iters_num': 10000, 'batch_size': 149}. Best is trial 14 with value: 0.9527.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(에폭) --> train_acc : 96.27%, test_acc : 94.67%\n",
      "\n",
      "\n",
      "신경망 학습 시작 - 신경망: 7층\n",
      "learning_rate: 0.003808747172762521\n",
      "hidden_size: [15, 15, 15, 15, 15, 15]\n",
      "batch_size: 104\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-05-11 18:55:16,036] Trial 17 finished with value: 0.9442 and parameters: {'learning_rate': 0.003808747172762521, 'num_layers': 6, 'iters_num': 10000, 'batch_size': 104}. Best is trial 14 with value: 0.9527.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(에폭) --> train_acc : 95.35%, test_acc : 94.42%\n",
      "\n",
      "\n",
      "신경망 학습 시작 - 신경망: 6층\n",
      "learning_rate: 0.007652627798039342\n",
      "hidden_size: [15, 15, 15, 15, 15]\n",
      "batch_size: 223\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-05-11 18:55:55,198] Trial 18 finished with value: 0.9489 and parameters: {'learning_rate': 0.007652627798039342, 'num_layers': 5, 'iters_num': 10000, 'batch_size': 223}. Best is trial 14 with value: 0.9527.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(에폭) --> train_acc : 96.55%, test_acc : 94.89%\n",
      "\n",
      "\n",
      "신경망 학습 시작 - 신경망: 7층\n",
      "learning_rate: 0.009952462239675622\n",
      "hidden_size: [15, 15, 15, 15, 15, 15]\n",
      "batch_size: 297\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-05-11 18:56:49,441] Trial 19 finished with value: 0.9503 and parameters: {'learning_rate': 0.009952462239675622, 'num_layers': 6, 'iters_num': 10000, 'batch_size': 297}. Best is trial 14 with value: 0.9527.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(에폭) --> train_acc : 96.63%, test_acc : 95.03%\n",
      "\n",
      "\n",
      "신경망 학습 시작 - 신경망: 6층\n",
      "learning_rate: 0.014139985264123568\n",
      "hidden_size: [15, 15, 15, 15, 15]\n",
      "batch_size: 159\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-05-11 18:57:11,006] Trial 20 finished with value: 0.9464 and parameters: {'learning_rate': 0.014139985264123568, 'num_layers': 5, 'iters_num': 10000, 'batch_size': 159}. Best is trial 14 with value: 0.9527.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(에폭) --> train_acc : 96.05%, test_acc : 94.64%\n",
      "\n",
      "\n",
      "신경망 학습 시작 - 신경망: 5층\n",
      "learning_rate: 0.01896441577127942\n",
      "hidden_size: [15, 15, 15, 15]\n",
      "batch_size: 273\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-05-11 18:57:53,035] Trial 21 finished with value: 0.9507 and parameters: {'learning_rate': 0.01896441577127942, 'num_layers': 4, 'iters_num': 10000, 'batch_size': 273}. Best is trial 14 with value: 0.9527.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(에폭) --> train_acc : 96.62%, test_acc : 95.07%\n",
      "\n",
      "\n",
      "신경망 학습 시작 - 신경망: 4층\n",
      "learning_rate: 0.01641082171370168\n",
      "hidden_size: [15, 15, 15]\n",
      "batch_size: 247\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-05-11 18:58:28,131] Trial 22 finished with value: 0.9494 and parameters: {'learning_rate': 0.01641082171370168, 'num_layers': 3, 'iters_num': 10000, 'batch_size': 247}. Best is trial 14 with value: 0.9527.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(에폭) --> train_acc : 96.09%, test_acc : 94.94%\n",
      "\n",
      "\n",
      "신경망 학습 시작 - 신경망: 5층\n",
      "learning_rate: 0.01601224626840206\n",
      "hidden_size: [15, 15, 15, 15]\n",
      "batch_size: 286\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-05-11 18:59:12,165] Trial 23 finished with value: 0.9519 and parameters: {'learning_rate': 0.01601224626840206, 'num_layers': 4, 'iters_num': 10000, 'batch_size': 286}. Best is trial 14 with value: 0.9527.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(에폭) --> train_acc : 96.65%, test_acc : 95.19%\n",
      "\n",
      "\n",
      "신경망 학습 시작 - 신경망: 6층\n",
      "learning_rate: 0.012913342312989512\n",
      "hidden_size: [15, 15, 15, 15, 15]\n",
      "batch_size: 201\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-05-11 18:59:48,050] Trial 24 finished with value: 0.9492 and parameters: {'learning_rate': 0.012913342312989512, 'num_layers': 5, 'iters_num': 10000, 'batch_size': 201}. Best is trial 14 with value: 0.9527.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(에폭) --> train_acc : 96.30%, test_acc : 94.92%\n",
      "\n",
      "\n",
      "신경망 학습 시작 - 신경망: 5층\n",
      "learning_rate: 0.010989992668613143\n",
      "hidden_size: [15, 15, 15, 15]\n",
      "batch_size: 288\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-05-11 19:00:32,338] Trial 25 finished with value: 0.9518 and parameters: {'learning_rate': 0.010989992668613143, 'num_layers': 4, 'iters_num': 10000, 'batch_size': 288}. Best is trial 14 with value: 0.9527.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(에폭) --> train_acc : 96.62%, test_acc : 95.18%\n",
      "\n",
      "\n",
      "신경망 학습 시작 - 신경망: 5층\n",
      "learning_rate: 0.015702010787114747\n",
      "hidden_size: [15, 15, 15, 15]\n",
      "batch_size: 285\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-05-11 19:01:16,452] Trial 26 finished with value: 0.9517 and parameters: {'learning_rate': 0.015702010787114747, 'num_layers': 4, 'iters_num': 10000, 'batch_size': 285}. Best is trial 14 with value: 0.9527.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(에폭) --> train_acc : 96.56%, test_acc : 95.17%\n",
      "\n",
      "\n",
      "신경망 학습 시작 - 신경망: 4층\n",
      "learning_rate: 0.010365172770391461\n",
      "hidden_size: [15, 15, 15]\n",
      "batch_size: 283\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-05-11 19:01:55,669] Trial 27 finished with value: 0.9493 and parameters: {'learning_rate': 0.010365172770391461, 'num_layers': 3, 'iters_num': 10000, 'batch_size': 283}. Best is trial 14 with value: 0.9527.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(에폭) --> train_acc : 96.06%, test_acc : 94.93%\n",
      "\n",
      "\n",
      "신경망 학습 시작 - 신경망: 5층\n",
      "learning_rate: 0.01397210023629437\n",
      "hidden_size: [15, 15, 15, 15]\n",
      "batch_size: 252\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-05-11 19:02:35,286] Trial 28 finished with value: 0.9473 and parameters: {'learning_rate': 0.01397210023629437, 'num_layers': 4, 'iters_num': 10000, 'batch_size': 252}. Best is trial 14 with value: 0.9527.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(에폭) --> train_acc : 96.05%, test_acc : 94.73%\n",
      "\n",
      "\n",
      "신경망 학습 시작 - 신경망: 4층\n",
      "learning_rate: 0.011087619415084796\n",
      "hidden_size: [15, 15, 15]\n",
      "batch_size: 287\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-05-11 19:03:15,407] Trial 29 finished with value: 0.95 and parameters: {'learning_rate': 0.011087619415084796, 'num_layers': 3, 'iters_num': 10000, 'batch_size': 287}. Best is trial 14 with value: 0.9527.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(에폭) --> train_acc : 96.07%, test_acc : 95.00%\n",
      "\n",
      "\n",
      "신경망 학습 시작 - 신경망: 5층\n",
      "learning_rate: 0.013172644662125687\n",
      "hidden_size: [15, 15, 15, 15]\n",
      "batch_size: 257\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-05-11 19:03:56,266] Trial 30 finished with value: 0.9488 and parameters: {'learning_rate': 0.013172644662125687, 'num_layers': 4, 'iters_num': 10000, 'batch_size': 257}. Best is trial 14 with value: 0.9527.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(에폭) --> train_acc : 96.48%, test_acc : 94.88%\n",
      "\n",
      "\n",
      "신경망 학습 시작 - 신경망: 5층\n",
      "learning_rate: 0.015686021855758722\n",
      "hidden_size: [15, 15, 15, 15]\n",
      "batch_size: 288\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-05-11 19:04:50,059] Trial 31 finished with value: 0.9472 and parameters: {'learning_rate': 0.015686021855758722, 'num_layers': 4, 'iters_num': 10000, 'batch_size': 288}. Best is trial 14 with value: 0.9527.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(에폭) --> train_acc : 96.38%, test_acc : 94.72%\n",
      "\n",
      "\n",
      "신경망 학습 시작 - 신경망: 5층\n",
      "learning_rate: 0.015706855894244295\n",
      "hidden_size: [15, 15, 15, 15]\n",
      "batch_size: 277\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-05-11 19:05:44,395] Trial 32 finished with value: 0.9505 and parameters: {'learning_rate': 0.015706855894244295, 'num_layers': 4, 'iters_num': 10000, 'batch_size': 277}. Best is trial 14 with value: 0.9527.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(에폭) --> train_acc : 96.52%, test_acc : 95.05%\n",
      "\n",
      "\n",
      "신경망 학습 시작 - 신경망: 6층\n",
      "learning_rate: 0.018499758898926015\n",
      "hidden_size: [15, 15, 15, 15, 15]\n",
      "batch_size: 300\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-05-11 19:06:48,032] Trial 33 finished with value: 0.9449 and parameters: {'learning_rate': 0.018499758898926015, 'num_layers': 5, 'iters_num': 10000, 'batch_size': 300}. Best is trial 14 with value: 0.9527.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(에폭) --> train_acc : 96.51%, test_acc : 94.49%\n",
      "\n",
      "\n",
      "신경망 학습 시작 - 신경망: 5층\n",
      "learning_rate: 0.015778120407829728\n",
      "hidden_size: [15, 15, 15, 15]\n",
      "batch_size: 240\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-05-11 19:07:33,354] Trial 34 finished with value: 0.9492 and parameters: {'learning_rate': 0.015778120407829728, 'num_layers': 4, 'iters_num': 10000, 'batch_size': 240}. Best is trial 14 with value: 0.9527.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(에폭) --> train_acc : 96.20%, test_acc : 94.92%\n",
      "\n",
      "\n",
      "신경망 학습 시작 - 신경망: 4층\n",
      "learning_rate: 0.006642374177688582\n",
      "hidden_size: [15, 15, 15]\n",
      "batch_size: 265\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-05-11 19:08:15,534] Trial 35 finished with value: 0.948 and parameters: {'learning_rate': 0.006642374177688582, 'num_layers': 3, 'iters_num': 10000, 'batch_size': 265}. Best is trial 14 with value: 0.9527.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(에폭) --> train_acc : 95.83%, test_acc : 94.80%\n",
      "\n",
      "\n",
      "신경망 학습 시작 - 신경망: 5층\n",
      "learning_rate: 0.017881609428602094\n",
      "hidden_size: [15, 15, 15, 15]\n",
      "batch_size: 288\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-05-11 19:09:10,911] Trial 36 finished with value: 0.9494 and parameters: {'learning_rate': 0.017881609428602094, 'num_layers': 4, 'iters_num': 10000, 'batch_size': 288}. Best is trial 14 with value: 0.9527.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(에폭) --> train_acc : 96.56%, test_acc : 94.94%\n",
      "\n",
      "\n",
      "신경망 학습 시작 - 신경망: 5층\n",
      "learning_rate: 0.017066721402060354\n",
      "hidden_size: [15, 15, 15, 15]\n",
      "batch_size: 261\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-05-11 19:10:00,247] Trial 37 finished with value: 0.9527 and parameters: {'learning_rate': 0.017066721402060354, 'num_layers': 4, 'iters_num': 10000, 'batch_size': 261}. Best is trial 14 with value: 0.9527.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(에폭) --> train_acc : 96.57%, test_acc : 95.27%\n",
      "\n",
      "\n",
      "신경망 학습 시작 - 신경망: 6층\n",
      "learning_rate: 0.017100269271177804\n",
      "hidden_size: [15, 15, 15, 15, 15]\n",
      "batch_size: 262\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-05-11 19:10:55,025] Trial 38 finished with value: 0.9506 and parameters: {'learning_rate': 0.017100269271177804, 'num_layers': 5, 'iters_num': 10000, 'batch_size': 262}. Best is trial 14 with value: 0.9527.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(에폭) --> train_acc : 96.73%, test_acc : 95.06%\n",
      "\n",
      "\n",
      "신경망 학습 시작 - 신경망: 6층\n",
      "learning_rate: 0.011346415876901512\n",
      "hidden_size: [15, 15, 15, 15, 15]\n",
      "batch_size: 277\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-05-11 19:11:52,408] Trial 39 finished with value: 0.9508 and parameters: {'learning_rate': 0.011346415876901512, 'num_layers': 5, 'iters_num': 10000, 'batch_size': 277}. Best is trial 14 with value: 0.9527.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(에폭) --> train_acc : 96.38%, test_acc : 95.08%\n",
      "\n",
      "\n",
      "신경망 학습 시작 - 신경망: 5층\n",
      "learning_rate: 0.013574587387696945\n",
      "hidden_size: [15, 15, 15, 15]\n",
      "batch_size: 217\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-05-11 19:12:36,589] Trial 40 finished with value: 0.9482 and parameters: {'learning_rate': 0.013574587387696945, 'num_layers': 4, 'iters_num': 10000, 'batch_size': 217}. Best is trial 14 with value: 0.9527.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(에폭) --> train_acc : 96.24%, test_acc : 94.82%\n",
      "\n",
      "\n",
      "신경망 학습 시작 - 신경망: 5층\n",
      "learning_rate: 0.014983078819073898\n",
      "hidden_size: [15, 15, 15, 15]\n",
      "batch_size: 284\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-05-11 19:13:23,713] Trial 41 finished with value: 0.9492 and parameters: {'learning_rate': 0.014983078819073898, 'num_layers': 4, 'iters_num': 10000, 'batch_size': 284}. Best is trial 14 with value: 0.9527.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(에폭) --> train_acc : 96.63%, test_acc : 94.92%\n",
      "\n",
      "\n",
      "신경망 학습 시작 - 신경망: 5층\n",
      "learning_rate: 0.016642760617386912\n",
      "hidden_size: [15, 15, 15, 15]\n",
      "batch_size: 269\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-05-11 19:14:08,982] Trial 42 finished with value: 0.9499 and parameters: {'learning_rate': 0.016642760617386912, 'num_layers': 4, 'iters_num': 10000, 'batch_size': 269}. Best is trial 14 with value: 0.9527.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(에폭) --> train_acc : 96.46%, test_acc : 94.99%\n",
      "\n",
      "\n",
      "신경망 학습 시작 - 신경망: 5층\n",
      "learning_rate: 0.0178696741133864\n",
      "hidden_size: [15, 15, 15, 15]\n",
      "batch_size: 291\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-05-11 19:15:00,017] Trial 43 finished with value: 0.9483 and parameters: {'learning_rate': 0.0178696741133864, 'num_layers': 4, 'iters_num': 10000, 'batch_size': 291}. Best is trial 14 with value: 0.9527.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(에폭) --> train_acc : 96.56%, test_acc : 94.83%\n",
      "\n",
      "\n",
      "신경망 학습 시작 - 신경망: 5층\n",
      "learning_rate: 0.01518256178244629\n",
      "hidden_size: [15, 15, 15, 15]\n",
      "batch_size: 276\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-05-11 19:15:52,056] Trial 44 finished with value: 0.9478 and parameters: {'learning_rate': 0.01518256178244629, 'num_layers': 4, 'iters_num': 10000, 'batch_size': 276}. Best is trial 14 with value: 0.9527.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(에폭) --> train_acc : 96.18%, test_acc : 94.78%\n",
      "\n",
      "\n",
      "신경망 학습 시작 - 신경망: 4층\n",
      "learning_rate: 0.017178191298785398\n",
      "hidden_size: [15, 15, 15]\n",
      "batch_size: 261\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-05-11 19:16:37,280] Trial 45 finished with value: 0.9527 and parameters: {'learning_rate': 0.017178191298785398, 'num_layers': 3, 'iters_num': 10000, 'batch_size': 261}. Best is trial 14 with value: 0.9527.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(에폭) --> train_acc : 96.38%, test_acc : 95.27%\n",
      "\n",
      "\n",
      "신경망 학습 시작 - 신경망: 4층\n",
      "learning_rate: 0.017325741465220125\n",
      "hidden_size: [15, 15, 15]\n",
      "batch_size: 240\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-05-11 19:17:19,365] Trial 46 finished with value: 0.9448 and parameters: {'learning_rate': 0.017325741465220125, 'num_layers': 3, 'iters_num': 10000, 'batch_size': 240}. Best is trial 14 with value: 0.9527.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(에폭) --> train_acc : 95.66%, test_acc : 94.48%\n",
      "\n",
      "\n",
      "신경망 학습 시작 - 신경망: 4층\n",
      "learning_rate: 0.016589279207301813\n",
      "hidden_size: [15, 15, 15]\n",
      "batch_size: 260\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[W 2024-05-11 19:17:47,958] Trial 47 failed with parameters: {'learning_rate': 0.016589279207301813, 'num_layers': 3, 'iters_num': 10000, 'batch_size': 260} because of the following error: KeyboardInterrupt().\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\kmn27\\anaconda3\\Lib\\site-packages\\optuna\\study\\_optimize.py\", line 196, in _run_trial\n",
      "    value_or_values = func(trial)\n",
      "                      ^^^^^^^^^^^\n",
      "  File \"C:\\Users\\kmn27\\AppData\\Local\\Temp\\ipykernel_11312\\625610421.py\", line 51, in objective\n",
      "    grad = network.gradient(x_batch, t_batch)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\kmn27\\AppData\\Local\\Temp\\ipykernel_11312\\1812632635.py\", line 81, in gradient\n",
      "    dout = layer.backward(dout)\n",
      "           ^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\kmn27\\AppData\\Local\\Temp\\ipykernel_11312\\3262000222.py\", line 24, in backward\n",
      "    dx = np.dot(dout, self.W.T)\n",
      "         ^^^^^^^^^^^^^^^^^^^^^^\n",
      "KeyboardInterrupt\n",
      "[W 2024-05-11 19:17:47,960] Trial 47 failed with value None.\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[151], line 76\u001b[0m\n\u001b[0;32m     72\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m test_acc_list[\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m]  \u001b[38;5;66;03m# 마지막 에포크의 테스트 정확도 사용\u001b[39;00m\n\u001b[0;32m     75\u001b[0m study \u001b[38;5;241m=\u001b[39m optuna\u001b[38;5;241m.\u001b[39mcreate_study(direction\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmaximize\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m---> 76\u001b[0m study\u001b[38;5;241m.\u001b[39moptimize(objective, n_trials\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m100\u001b[39m)  \u001b[38;5;66;03m# 100번의 튜닝 수행\u001b[39;00m\n\u001b[0;32m     78\u001b[0m best_params \u001b[38;5;241m=\u001b[39m study\u001b[38;5;241m.\u001b[39mbest_params\n\u001b[0;32m     79\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m최적의 하이퍼파라미터:\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\optuna\\study\\study.py:451\u001b[0m, in \u001b[0;36mStudy.optimize\u001b[1;34m(self, func, n_trials, timeout, n_jobs, catch, callbacks, gc_after_trial, show_progress_bar)\u001b[0m\n\u001b[0;32m    348\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21moptimize\u001b[39m(\n\u001b[0;32m    349\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[0;32m    350\u001b[0m     func: ObjectiveFuncType,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    357\u001b[0m     show_progress_bar: \u001b[38;5;28mbool\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m,\n\u001b[0;32m    358\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m    359\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Optimize an objective function.\u001b[39;00m\n\u001b[0;32m    360\u001b[0m \n\u001b[0;32m    361\u001b[0m \u001b[38;5;124;03m    Optimization is done by choosing a suitable set of hyperparameter values from a given\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    449\u001b[0m \u001b[38;5;124;03m            If nested invocation of this method occurs.\u001b[39;00m\n\u001b[0;32m    450\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m--> 451\u001b[0m     _optimize(\n\u001b[0;32m    452\u001b[0m         study\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m,\n\u001b[0;32m    453\u001b[0m         func\u001b[38;5;241m=\u001b[39mfunc,\n\u001b[0;32m    454\u001b[0m         n_trials\u001b[38;5;241m=\u001b[39mn_trials,\n\u001b[0;32m    455\u001b[0m         timeout\u001b[38;5;241m=\u001b[39mtimeout,\n\u001b[0;32m    456\u001b[0m         n_jobs\u001b[38;5;241m=\u001b[39mn_jobs,\n\u001b[0;32m    457\u001b[0m         catch\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mtuple\u001b[39m(catch) \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(catch, Iterable) \u001b[38;5;28;01melse\u001b[39;00m (catch,),\n\u001b[0;32m    458\u001b[0m         callbacks\u001b[38;5;241m=\u001b[39mcallbacks,\n\u001b[0;32m    459\u001b[0m         gc_after_trial\u001b[38;5;241m=\u001b[39mgc_after_trial,\n\u001b[0;32m    460\u001b[0m         show_progress_bar\u001b[38;5;241m=\u001b[39mshow_progress_bar,\n\u001b[0;32m    461\u001b[0m     )\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\optuna\\study\\_optimize.py:62\u001b[0m, in \u001b[0;36m_optimize\u001b[1;34m(study, func, n_trials, timeout, n_jobs, catch, callbacks, gc_after_trial, show_progress_bar)\u001b[0m\n\u001b[0;32m     60\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m     61\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m n_jobs \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m1\u001b[39m:\n\u001b[1;32m---> 62\u001b[0m         _optimize_sequential(\n\u001b[0;32m     63\u001b[0m             study,\n\u001b[0;32m     64\u001b[0m             func,\n\u001b[0;32m     65\u001b[0m             n_trials,\n\u001b[0;32m     66\u001b[0m             timeout,\n\u001b[0;32m     67\u001b[0m             catch,\n\u001b[0;32m     68\u001b[0m             callbacks,\n\u001b[0;32m     69\u001b[0m             gc_after_trial,\n\u001b[0;32m     70\u001b[0m             reseed_sampler_rng\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m,\n\u001b[0;32m     71\u001b[0m             time_start\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[0;32m     72\u001b[0m             progress_bar\u001b[38;5;241m=\u001b[39mprogress_bar,\n\u001b[0;32m     73\u001b[0m         )\n\u001b[0;32m     74\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m     75\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m n_jobs \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m:\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\optuna\\study\\_optimize.py:159\u001b[0m, in \u001b[0;36m_optimize_sequential\u001b[1;34m(study, func, n_trials, timeout, catch, callbacks, gc_after_trial, reseed_sampler_rng, time_start, progress_bar)\u001b[0m\n\u001b[0;32m    156\u001b[0m         \u001b[38;5;28;01mbreak\u001b[39;00m\n\u001b[0;32m    158\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 159\u001b[0m     frozen_trial \u001b[38;5;241m=\u001b[39m _run_trial(study, func, catch)\n\u001b[0;32m    160\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[0;32m    161\u001b[0m     \u001b[38;5;66;03m# The following line mitigates memory problems that can be occurred in some\u001b[39;00m\n\u001b[0;32m    162\u001b[0m     \u001b[38;5;66;03m# environments (e.g., services that use computing containers such as GitHub Actions).\u001b[39;00m\n\u001b[0;32m    163\u001b[0m     \u001b[38;5;66;03m# Please refer to the following PR for further details:\u001b[39;00m\n\u001b[0;32m    164\u001b[0m     \u001b[38;5;66;03m# https://github.com/optuna/optuna/pull/325.\u001b[39;00m\n\u001b[0;32m    165\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m gc_after_trial:\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\optuna\\study\\_optimize.py:247\u001b[0m, in \u001b[0;36m_run_trial\u001b[1;34m(study, func, catch)\u001b[0m\n\u001b[0;32m    240\u001b[0m         \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28;01mFalse\u001b[39;00m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mShould not reach.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    242\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m (\n\u001b[0;32m    243\u001b[0m     frozen_trial\u001b[38;5;241m.\u001b[39mstate \u001b[38;5;241m==\u001b[39m TrialState\u001b[38;5;241m.\u001b[39mFAIL\n\u001b[0;32m    244\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m func_err \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m    245\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(func_err, catch)\n\u001b[0;32m    246\u001b[0m ):\n\u001b[1;32m--> 247\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m func_err\n\u001b[0;32m    248\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m frozen_trial\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\optuna\\study\\_optimize.py:196\u001b[0m, in \u001b[0;36m_run_trial\u001b[1;34m(study, func, catch)\u001b[0m\n\u001b[0;32m    194\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m get_heartbeat_thread(trial\u001b[38;5;241m.\u001b[39m_trial_id, study\u001b[38;5;241m.\u001b[39m_storage):\n\u001b[0;32m    195\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 196\u001b[0m         value_or_values \u001b[38;5;241m=\u001b[39m func(trial)\n\u001b[0;32m    197\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m exceptions\u001b[38;5;241m.\u001b[39mTrialPruned \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m    198\u001b[0m         \u001b[38;5;66;03m# TODO(mamu): Handle multi-objective cases.\u001b[39;00m\n\u001b[0;32m    199\u001b[0m         state \u001b[38;5;241m=\u001b[39m TrialState\u001b[38;5;241m.\u001b[39mPRUNED\n",
      "Cell \u001b[1;32mIn[151], line 51\u001b[0m, in \u001b[0;36mobjective\u001b[1;34m(trial)\u001b[0m\n\u001b[0;32m     48\u001b[0m t_batch \u001b[38;5;241m=\u001b[39m t_train[batch_mask]\n\u001b[0;32m     50\u001b[0m \u001b[38;5;66;03m# 오차역전파법으로 기울기 계산\u001b[39;00m\n\u001b[1;32m---> 51\u001b[0m grad \u001b[38;5;241m=\u001b[39m network\u001b[38;5;241m.\u001b[39mgradient(x_batch, t_batch)\n\u001b[0;32m     53\u001b[0m \u001b[38;5;66;03m# SGD 학습, 모멘텀 학습, AdaGrad 학습\u001b[39;00m\n\u001b[0;32m     54\u001b[0m \u001b[38;5;66;03m#sgd.update(network.params, grad)\u001b[39;00m\n\u001b[0;32m     55\u001b[0m \u001b[38;5;66;03m#momentum.update(network.params, grad)\u001b[39;00m\n\u001b[0;32m     56\u001b[0m adaGrad\u001b[38;5;241m.\u001b[39mupdate(network\u001b[38;5;241m.\u001b[39mparams, grad)\n",
      "Cell \u001b[1;32mIn[150], line 81\u001b[0m, in \u001b[0;36mTwoLayerNet.gradient\u001b[1;34m(self, x, t)\u001b[0m\n\u001b[0;32m     79\u001b[0m layers\u001b[38;5;241m.\u001b[39mreverse()\n\u001b[0;32m     80\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m layer \u001b[38;5;129;01min\u001b[39;00m layers:\n\u001b[1;32m---> 81\u001b[0m     dout \u001b[38;5;241m=\u001b[39m layer\u001b[38;5;241m.\u001b[39mbackward(dout)\n\u001b[0;32m     83\u001b[0m \u001b[38;5;66;03m# 기울기\u001b[39;00m\n\u001b[0;32m     84\u001b[0m grads \u001b[38;5;241m=\u001b[39m {}\n",
      "Cell \u001b[1;32mIn[135], line 24\u001b[0m, in \u001b[0;36mAffine.backward\u001b[1;34m(self, dout)\u001b[0m\n\u001b[0;32m     23\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mbackward\u001b[39m(\u001b[38;5;28mself\u001b[39m, dout):\n\u001b[1;32m---> 24\u001b[0m     dx \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mdot(dout, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mW\u001b[38;5;241m.\u001b[39mT)\n\u001b[0;32m     25\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdW \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mdot(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mx\u001b[38;5;241m.\u001b[39mT, dout)\n\u001b[0;32m     26\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdb \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39msum(dout, axis\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0\u001b[39m)\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "import optuna\n",
    "import numpy as np\n",
    "\n",
    "# 기울기 최적화 함수들\n",
    "\n",
    "# 하이퍼파라미터 범위 설정\n",
    "learning_rate_range = [0.001, 0.019]\n",
    "num_layers_range = (3, 6)\n",
    "iters_num_range = (10000, 10000)  # Fixed iterations (can be removed for further tuning)\n",
    "batch_size_range = (100, 300)\n",
    "\n",
    "def objective(trial):\n",
    "    # 하이퍼파라미터 설정\n",
    "    learning_rate = trial.suggest_float(\"learning_rate\", learning_rate_range[0], learning_rate_range[1])\n",
    "    #hidden_size = [trial.suggest_int(\"hidden_size_{}\".format(i), hidden_size_range[i][0], hidden_size_range[i][1]) for i in range(len(hidden_size_range))]\n",
    "    num_layers = trial.suggest_int(\"num_layers\", num_layers_range[0], num_layers_range[1])\n",
    "    hidden_size = [15] * num_layers\n",
    "    iters_num = trial.suggest_int(\"iters_num\", iters_num_range[0], iters_num_range[1])\n",
    "    batch_size = trial.suggest_int(\"batch_size\", batch_size_range[0], batch_size_range[1])\n",
    "\n",
    "    # 모델 생성\n",
    "    network = TwoLayerNet(input_size=784, hidden_size=hidden_size, output_size=10)\n",
    "\n",
    "    # 최적화 알고리즘 설정\n",
    "    #optimizer = Momentum()  # SGD, Momentum, AdaGrad 등 사용 가능\n",
    "    sgd = SGD()\n",
    "    momentum = Momentum()\n",
    "    adaGrad = AdaGrad()\n",
    "\n",
    "    \n",
    "    # 학습 및 평가\n",
    "    train_loss_list = []\n",
    "    train_acc_list = []\n",
    "    test_acc_list = []\n",
    "\n",
    "    train_size = x_train.shape[0]\n",
    "    iter_per_epoch = max(train_size // batch_size, 1)\n",
    "\n",
    "    print(\"learning_rate:\", learning_rate)\n",
    "    print(\"hidden_size:\", hidden_size)\n",
    "    #print(\"iters_num:\", iters_num)\n",
    "    print(\"batch_size:\", batch_size)\n",
    "    \n",
    "    for i in range(iters_num):\n",
    "        # 배치 데이터 추출\n",
    "        batch_mask = np.random.choice(train_size, batch_size)\n",
    "        x_batch = x_train[batch_mask]\n",
    "        t_batch = t_train[batch_mask]\n",
    "\n",
    "        # 오차역전파법으로 기울기 계산\n",
    "        grad = network.gradient(x_batch, t_batch)\n",
    "\n",
    "        # SGD 학습, 모멘텀 학습, AdaGrad 학습\n",
    "        #sgd.update(network.params, grad)\n",
    "        #momentum.update(network.params, grad)\n",
    "        adaGrad.update(network.params, grad)\n",
    "\n",
    "        # 손실 계산\n",
    "        loss = network.loss(x_batch, t_batch)\n",
    "        train_loss_list.append(loss)\n",
    "\n",
    "        # 에포크 마다 평가\n",
    "        if i % iter_per_epoch == 0:\n",
    "            train_acc = network.accuracy(x_train, t_train)\n",
    "            test_acc = network.accuracy(x_test, t_test)\n",
    "            train_acc_list.append(train_acc)\n",
    "            test_acc_list.append(test_acc)\n",
    "            #print(\"%2d 번째 학습(에폭) --> train_acc : %.2f%%, test_acc : %.2f%%\" % (len(train_acc_list), train_acc*100, test_acc*100))\n",
    "    print(\"(에폭) --> train_acc : %.2f%%, test_acc : %.2f%%\" % (train_acc_list[-1]*100, test_acc_list[-1]*100))\n",
    "    # 테스트 정확도 반환\n",
    "    \n",
    "    return test_acc_list[-1]  # 마지막 에포크의 테스트 정확도 사용\n",
    "\n",
    "\n",
    "study = optuna.create_study(direction=\"maximize\")\n",
    "study.optimize(objective, n_trials=100)  # 100번의 튜닝 수행\n",
    "\n",
    "best_params = study.best_params\n",
    "print(\"최적의 하이퍼파라미터:\")\n",
    "print(\"learning_rate:\", best_params[\"learning_rate\"])\n",
    "print(\"hidden_size:\", best_params[\"num_layers\"])\n",
    "print(\"최고의 테스트 정확도:\", study.best_value)\n"
   ]
  },
  {
   "cell_type": "raw",
   "id": "ac5fa1b5-7f89-489d-a9a1-284989870f4e",
   "metadata": {},
   "source": [
    "learning_rate: 0.010963056767964934\n",
    "iters_num: 4\n",
    "최고의 테스트 정확도: 0.9536"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d995a78f-7dfe-45da-8191-272f4320de8c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "98fcfaad-c560-4179-824c-0ed1d3fc43f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import tensorflow as tf \n",
    "from tensorflow.python.client import device_lib\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"0\"\n",
    "\n",
    "print(device_lib.list_local_devices() )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "063a9e11-fdfd-4db5-855b-f2a0b879f7ef",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ff54f8b-4e11-48b4-9620-94b5d1a74ae5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd19b0ce-7b61-4de0-b6ed-e86c5692856a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c0d9b968-c02c-40eb-b72b-1335e09a0f6a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd912137-5af2-4565-9eb2-ef5dcc1917ed",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e68d64b-6fbe-4dd4-9010-74a2499f5505",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1162bddb-0828-45fd-9529-6832eef0fe5e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d3fd7a9-860f-42c4-80f6-18d0a0b84d80",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d9791f8-3241-48bd-a23f-1eed887c4530",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65c9ef26-b09d-4982-a7a9-8fd7cf5910c8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9fa2413d-7467-4e74-9d48-7ca28020079e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
