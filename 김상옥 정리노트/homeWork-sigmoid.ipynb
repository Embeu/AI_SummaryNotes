{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "512447ed-ca6f-4d09-bf72-ab84587f7798",
   "metadata": {},
   "source": [
    "# ◇ 라이브러리 설정 MNIST, numpy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "703a29df-fcf6-41e2-a7f6-8f9123a1d087",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import sys, os\n",
    "sys.path.append(os.pardir)\n",
    "import numpy as np\n",
    "from dataset.mnist import load_mnist\n",
    "from collections import OrderedDict"
   ]
  },
  {
   "attachments": {
    "8d7f22dd-1fe5-4f25-9a13-ed54f875196f.png": {
     "image/png": "iVBORw0KGgoAAAANSUhEUgAAASIAAACdCAYAAAAQVXWiAAAAAXNSR0IArs4c6QAAAARnQU1BAACxjwv8YQUAAAAJcEhZcwAADsMAAA7DAcdvqGQAACsVSURBVHhe7Z0HlBXVGcfv7rJLWWDpTRGDJSoWxGg0GkWNaGzxxN6OikaxchJLjElU0IhR0RMlxoiVGMuxHEVNNJ5gL2ABsaMSVDrIAkvZwu5mfvfdC7PDK/P2vXnz3sz3O+ednXn7yryZe//3a/dOWauDEgRBCJFy81cQBCE0RIgEQQgdESJBEEJHhEgQhNARIRIEIXREiARBCB0RIkEQQkeESBCE0BEhEgQhdESIBEEIHREiQRBCR4RIEITQESESBCF0RIgEQQgdESJBEEJHhEgQhNARIRIEIXREiARBCB0RIkEQQkeESBCE0BEhEgQhdESIBEEIHREiQRBCR4RIEGJOc3Ozamxs1H/DQm6wKAgxo6WlRTU1Nan6+nr9qK2tVQ0NDWq77bZTXbp0Ma8qLCJEghAD6Obr1q1Tq1at0uKD9VNXV6dWrFihqqqq1M4776x69uypysrKzDsKi7hmghATli9frl2w6upqtXbtWi1AnTt3VsOGDVM9evQITYRAhEgQYgAig8WzbNkytXDhQrXVVltpCwlLqFevXqq8PFwpENdMECIOXXzlypVq7ty5en/gwIHqu+++UzvssIOqqanRz4WNCJHQBgKZPGgW9mGzKjzczaWiokKb9zzsiMrIyzaPME19IXEtCUL/73//09fiBz/4gb5mH3zwgfrhD3+o3bFiQYQo5nD5yaAgMvzFXCeIuWHDBv0/RKayslJ16tRJdezYsY242JQvwU+7jQDxum7duum/9v0dOnQw7xKChuvGNcENwxIaMmSI6t69+8Zrx3VCkIoJEaIYYsVnzZo1+kGjtQJCIBPRQTx4ZIP9XEQJQVu/fr3e5rMJitIZ+FtsnSBKcL4JSpMdI/bTp0+fkjjfIkQxA3FYsmSJFoquXbvqB+KA5ZLvBkvTwrLCPbD1KuzTQQic8p1CfuBcf//992rx4sWqd+/e+hxzfkvFPRYhigkIz7x587QQDB48WFs+uEtYK4WC7+ZBh0EM+/btqwOn4rblBqn4L7/8Ug8qW265pRagQl7XfCBCFHGwgBAgTPZtttlGC1DYoyRNjkAqMYxvvvlGixHiWCqjd7GAqHNtiemRAcOlLtVzKEIUUYjVLFq0SFfObr311jpNW4yNlOa3YMECbSGR1SGTU2qjeaFBgHBzScFvscUWql+/fiUv4jkJEW/F9w8iviC0DywNRkgsDQKVNNJScH1oR99++60WITpXKY/uQUG2CzeMa4tly3kiwRAFchIilPmrr77SjcYGPr0pXqFwEBTGCqJT2zhQKUFHY6THOkJACbqKdZQYXBAgXFks3UGDBum+FqV+lrNrxonhJDEK2/krjMScKGlEhYPzj6lONoogcKkGgK2VzTQEtqmBybaMIEpwLsiE8RdxjqrrmrcYEaqNKPHgxK1evVqfOERJrKTg4PLZeEGxBKPzAdYR9TBYR9tvv722uuME/YnsIvEzMmHE+KIsyIEEqzmJPOggjGx0DE6mBCLzC5cOc33p0qVq2223jVxn5fcxoJEZCnOtnEJDkekXX3yhrVtcbKzbqA/kgQiRF1LIxC4Y4fD7CbLZYiuxlNqHFSEsBlK3UR4tqRJmvhRiVGpxL79wPfEmmJiKG2bT8XGhIEJkwdxmhJs/f74+8dSPMCeJTiRZN/9gbVq3JeoiZCEGRifFTaMSPCpYAbJV0ZRahL02UBgUVIjcoPqcfIQJ6wgfmNFO0rbp4XLhiiFEzKCOU1UyYmQtoyiIEVlnJqUyoND+ianSF+JIaEJk4WIw/QBBIuvG6M6IYC0lYRNcKuJuuLlxEyELv596IyzBUq2hwaKlvSNA/AYECGGN8wAcuhBZOAxMVCwlGhsjhR0l4hKkzAQWgQ3cxi2L5AZrEDcGMSo1MSZeSoaT9k6slLYtCZwiEiI3jBjEk8gekL6kUI/sATOK42gFAOeAGAmNl+U0goD5aFTtzpkzR9eB7b///mlHaaxZsqJcF17vhhGfIDPHm++ORpOlXfD91BmVgiVBe0Y8STAQB8Lil7joJopSimm4uGWkL1lTd7fddtMjCSvLkdbEhStC/QwMhJlGjADRgIMAEXriiSfUUUcdpY488kgtMOlAGG+55RZ1//33J3WhOeZJkyaphx56SFu6+QThGTBggD4GrOdihnaKKL///vtajHbddVcdehARaktRWkSpoHG7raT+/fvr0ZiLyiOqPratmiZjFKRFSEcZP368uuOOO9SsWbP0AuvJYFAYO3asTi5MmDAhpZvIcV9yySVqv/32U2eddVbeLSMGJFxVCjmLzVWlrdJGCa7TxYrxGIuJkhIiN4zgzCwnXkCmgfokAn5c7Cj53Lgfn3zySUEK+shijh49WltDL7zwgj6nXhArLKFHHnlEvfzyy9pqTQeu3hFHHKH+/ve/q3333dc8mx9ouliKnKMgXMD2wDER56RdEudEzIl1Cukp2R6L+GCe77TTTnoSoA0CMkLSCBCqKMBvYu5YIQL2lAUgegceeODG76NTIT4W4kc33nijuu666zKKEBDDOeOMM9T555+vLaR8ggXMFCI+l+sfNrigZDRpg7TPHXfcUUTIJyVvOjAKEihlRGQ9G0ZxTGJWrGNlABopZnIpQlkDoyouaNAwkuPyEnM54IADdKfC8jn66KPV1VdfvbGj//Wvf9UCcPDBB+t9P2ARffTRR+rVV181z+QP4lNMH6Lzh2Xc076wJj/77DO9Tzsk2xvXxEp7iIwPQ+ewhZFUbOPK0BjoXLNnz9YmfL6DpkFDfIHYQiECm4j3a6+9pgOpPC677DJ9PnF/CWJz/hCpl156Sc9ry8ZCI7bFgHH33XebZ/ILAXw6fb4tLj8Qp8KK5DxR24WVTnggqvHKoIhOMMUFjZ5ORJaJxrHLLrvo0ZIALCMzVkZYo6dfbGYwqFS9FyyeadOmaQGfMmWKOuecc9RFF12kRZBzSWCaAjyOi1KKbEAkeA9ZzyBcKDo9LiBuY6HAXWWgwPImHY84U5wYpfhkIYn8WaOR0pmwkvbcc081dOhQXctBOpUKXRsDKSZh4lhwNTjWQoHA0Kk4N4ceeqjafffddYYSaxK3F5eXNHQusTcsUlyYIMAKwUUPOp1PW+E3fPjhh/o7GeSwyMQCyo3YyTcjO6M+tUlsE0eiNonGRUzGHZgNC44DCjmF4dNPP9XuBW4UMSJiL2TF6GDHHXfcxvKIXDtckIKPZWKrlvMNmTlcP9oK52nYsGF6cCuE2xwHYmtH0tEY5cm6YdbbrBtWElYBllIYVhLfSdaPTGChzHy+8/HHH9fn4+yzz9a1WTB16lRdEnHQQQfpfdxEzlt7rCK+g04bVEEmYKHgBlohzwe2do12QUYMF9O6YUL+iL1DS2fHMqKBERimM9LR8P+xlpimUMisG+4LoljISZCIxNtvv61dQVwyvpdzQC0RGSDEg4AsgVjcHxIA2YCVibjaZV+CBDeSwHo+4BwwOLFsDQF82oe4YcEQeyFyw2jKqE+HodFhldCBCHLTIBGIoK0kRnNEiABxOujcdgkJgrQcIw+2OWbiOX7dTDouMSnmltnaIPapK/rxj3+snn32Wd0pOTejRo3SAp2NVURH5neddtppaV0Zzq2d9Mz5/vrrr9Xnn3+uj4XfyW/CRUoH2TziXblkSDkOfjuJDT6PtsB5ETcsOESIkmCzblhKWAnMD0IciA/QOIknBSFIfCadiO9N5ZYhPh9//LFOtWOZII50EmaiE/timw5LRfObb76pLZlMrgopeVyuww8/fOP38hkcz2OPPaY7I+cAS4DCRMSA9/jllVde0Z9x6qmnmmfagmDyW+xcQlwhLC8GAtwge/92xGHmzJlacInTJLsGvA7B5DPaA3EgvoO/xBH5bs6NWEHBUrJTPMKCjo8FQRwJN47OgmjRgXNtrIziuIS4iQifhUuEmJDVQgSYNkCNVCasS4QFQ+eklCGbToWI4erglri5/PLL1euvv64FhrhMOhC0n/zkJ+rCCy/UIuaG42M6CbEXvoffxPFlgponYjaIDQMF7pJbuBFrHgSv/cD55dzzmVxfxM99/oXgESFqJ8SN6GSM5HQo3DlGcTpSeytq6QR0Biwb27H4bDoqD+I1BJJTWUup4FixJlhGhE6W63IquE/HH3+8dtOoN0rVabEqmA7C39tvv908u0lYsX6wOBCh9rg9nC+Em+/nM6w7y2dzXThfmX4nLiaiZcWwPedXyB0Rohzh9DFC4yogTAgR1geilG2BG++nU9hZ73QSxAMxIk6RyfrIBAJCDAk3iUyhH+sjFQjbtddeqw455BB12GGHbSZGWCtMjMWNxRqyQWpEkRgQViXHwHnKBc4N8SPOG9YR58haNwwO/NZkYFnyHixbXkMgXjJh4SFClEdo3IzSZNoYlREhYjYIk+30dEQ6jo09WLgMdB5ey3voTARq6Rx0sFwsGDeIG98DuC7t/VyOF0FhftWIESM2EyLOAS4h7qAVG95D50eE+O58uT/2WAiKUwfFOWOb7+VcuuH8Y6FxDLzOTiiWGFC4iBAFAKcUIbGWEp2EOXB28iqdl06I62A7Ix2EokJcJ1wMLBeEDEso39kajo2MFKKHJVAoVwSR5ncFcScOK3IE6VlMj9gYv8sdS+N6kI3j9zNRNl1SQCgschUCgNEVMcEdIfBMxyD2QDyDqSVs00GweGz2x4oX77MFlQhVECljLDE+26bVCwUCHFQgmHOO9YPYIzZYO1h/CDznlpgRGU/OPULoDXAL4SJXImBo7Lg/WERUcSMCPEfsB5EhE8Y2HYbnESMCp3TYXGI4maCjYm1hoRQCRA8RwAoJElwtLC9ECAsIK+ndd9/V5xUXkmMIQtyF3BAhKiB0CkZurBBS/1g/xJUQImpoEB4sJFymIKwGLxwD8J1Bwm9EiLAOgwbRx+0imI5lSXkA9UDEpMQCKl4kRlRAsHrolGR67F9cMEZrMmaM5HQk3KZCrexHUBmrbI899ggsYIuFx+8thBAB5xM3kPM5fPhwbf0JxY0IUZFAcJWqagSJJUb9ZrOwsqigxuJASHDppk+fri644AJfYsblZ54Zc8yCsML4fCqhWS4j028im/jOO+9oC5EYDjVKQIbr4Ycf1lNQOM5MrhXfifgRuOb1uZY9xBlEHQseMecR1GAltmqRYC84qWS/IkRnO/fcc/WCZswJI83P7Hlu4+M3vkTDIq6CALYHrDzKAQgQUzvEvhviNPweP7+JY6as4Z577lFXXHHFxrWLEOh//OMf6oYbbtCflwl+kw1GyzibG5xvAv2UYjC1iG2uh/c654pYREUCozfCwpwx75SKZODSsW4QIjJlyhSdMcKqohjyhBNOUA8++KB5ZWaIERFLIbuXLbiXWDDU7CBm1OiwzXER66LR8pxft4wG/tRTT+kJsnfddZc688wztVuHOHGMV111lS8Lh2A1HYeiRltxLWQP7i3XlfaFVHA9ib2xzaBB9hfLO9f4mwhRkcAMc9wrYhp+qo2xfJ555hn1xhtvaPECXKC9995b39SQxcz8QhNg3hgNK1t4L0JDNsy6TIgktVOAOc+UFebk+QVBJaPH/dCef/55/RzCStCZ8+MHBI10PWIoQtR+ECIsdVsYyqCFpcq1ZrBBiEh65OqyiRAVCE5zuouFRYR7Q9A4U6yGDkanPOWUU7ToAJ/PzQ7HjRunLRTmTfmF9xJn2muvvcwz/sEiQkRplPw+slWMoFgt1PQgSO2pouaWRmQScQUQtsmTJ2vrCAvHL0zaJfCfapqHkBkGGdqmTa4gPIgSA0+u4uNGYkQFgs7JaMKFpWNxUd1gOfCcn4v7wAMPaPHAKrLg1t17772642UjQha+F8sh2wfHTWwHESUDh+WDmCKUVG3zmvaY7cccc4x2r8h+UQeEVeWuks6EjK/5geuLu08NHNcVFxuLPZ8iBCJEBQIhwuXAYmCEwYqg82IxIExcWDqPnyCgvT+YdckIEt95550668SyrnweopAN7W1YvI/Jq6xXRLCceIE7MI1IISjZQvwLYcZSw23ETcumEJHzyCPfHSZuMJAUwr0VIUoBjRhzlAcZLTo3D/xlOj4PxIX0OQ9EhjQzD2I9CA0P3CQyDnZxfrIQfA6vp36Hu0Ew6vNZwPdlwlpTiBgW1tNPP60/F8sD9+q2227Tx+wXhMJvls0LHZ33phIJXDJ+d7YwAuNSEaT+2c9+lvVNJvn9nCexjEqDko4R2c7GT6AD89duJ3seAeAvEIQD9+uBz6Rz8aBj2xHVjvI8Z0cHOp/dTvW8BeGxz7ONm0ZHs5MvYcaMGdoFyRQH4UaFY8aM0e8l/nLsscfqTNvYsWN1hyWwy62T/FoQxGEQI9y6fINQYqlR35QtLKhG0Jrfm22MiewOMSKuLy4ibl0QdVJCfghUiOjgtpPbEcq9zVezbd0RhMJu0zHs690mtnubTm3jD4zKdts2OF5ni7BSbfvFz2vTvYaUJ5YPmSk6hk152vfwWyksZC4U1kA6eC1Fi0yaxRVDkLA6XnzxRZ01Yz+b30bwm9iOnfKRTzhWsnnEF7KB608BI+tlEwjPFixQ3GCEDOsVK5W2RoyD3+lXpIXC4EuI6ESM4DQqKyzWdQE+wl5Y9zZWhLUM2LbmP/+3FobbrHc/z1/7fBSwAmvF0gvnlqAs5wshKlQ1MMdFDGbkyJEpjy1X/GavbFOkXbEc7Yknnqj22Wcf/Vw28Dksc0IbIn5lRRlxI6iPRcpAYFd1dA8IQjj4EiJrnXCxrDhw8aIkFGGDINBhOc9YTLhYhegcuGVYU7iEQUHgnGJEpq6kAlcZi5DAqK3SPv30081/s4PPIvZG8DxZpo1zzedbl5RzbQOytGkRpcLjawjkAuHuMEpjwaQLTgrtg8aP20ZqFAsUNyJo6IR0ers0bVDQyXG76fyp4DdTNU2ci7jSSSedZP6THYgMQXzOJ+53MhhEOSaE0WYeOQ8kF3DnEGYf47OQR6SgsYggwIrlgGtCRyFuE9ToTIe17ksQQWoviBDfx62arfvtBiuGFSoZ7AhspxKRTCB4TO2wn+PXxcUS5Rg4TjKYdAtiSdZSEoJFhKgI4BLQgQiwsoojlat0CGasB7GQGN9HzI/JqghDoToa9VMIKwHjIAQWcZ09e7Z2tRB1XLNs416cGwYCrEUsK+JJTKDFXSbGFdTAEHdEiEIC14v6I1wSRIeGz4jMCE5VMg2eTkW2ye+o7hdcH27lw8L2dLJCQQenpopAMR07n52aZoxFRdYRYUXY21Nh7obPxFJC1GwsDSsVoZPQRH4RIQoBhAf3gc6IEGApUJBI7I3n+EtjJ15Bip6aIMQo147Lpea77drRdNpCw+9EBPmddn5ariBwFIdiPSI+iB1//UwezgZEiYJV3Ge+y9aASdYtd0SIQgBrCBcMCwh3glgEbhnLcDCSI0CknYmlkHFipCerRdFisviKH/hOvgPRwxLys9RIUGD9ES/C1cllmQ7OHeeLz0LUEDc+G6HFrc3WLfMLXQYriVIAhJ3v5hpybXiIKGWPCFGBoaPYYjtGWEx9Ko8RB6weRnc6FnEUW3eDS8BUEToWnY0Aqh9B4tIiQHQWRnE6LoJWDBXG/E6sC9xEsoU2KOynE/O7EHFiOAg11g/v572cSz47V7fML1xPgtu42FwfOzOdaynum39EiAoEooMA8aDT4BbRaWjE3N7GHQdipKVTuWuJ6Fy8lwYPuB2MwrhxdGA7+iM2uD90EDoqIsT/qKfhO4OyEtoDTQ/LgoAwlg0CSfyIv/wue6y8jvPHb0KUER8EFqvOxoTs66gfIi3f3qxbe+G8I44cG7+J64bbzTEW+lhKERGigOH0IgbUqCBAmPF0NBoqnQnodG4QEmJDG1Pdjgg5G/qzECQaPJYEQsM+ncB9GRmJ+Uw6Ad/J97XXpSsEVjx5EMCnI9vfxHHzGxElfhdChQgj3PxGK9TAe611GRb2GvFbGGQYPDhOLF+Ou5gGgmJChChAGMFJkdMo7eJgfhvit5Mnq6onnlCtn3yi9yscl6zjyJGq+oILVIehQ3WDx0rgr31Y+A77cHfUUgABsiLk/k38jky/iZtXMj2G81wMcPyIEu2ArBuDB5YpD7GS2iJCFACcUkZmRAgByiY71EzcZPx4tX7qVPNMW8p79lQ9H3hAVWU5iTTqYA3h0qabRhI2DBy4oVRx404SB8RqLbXBIghEiPIIDQ23ydbKkN71ul3paFm6VNWOGaMaZ8wwzyQHEer9zDNmT+C8U3NF1jGb8x0muJ8kLHDdiPURD0SccD/jKEwiRHkAV4IgKlkg3DAqerN1D1qWLUuI0PTp5pn0dB83TlW7loqNKzRfrAzicIWYqpJvEFFiSVjQ/BZEiWwpMbBijuvlGxGiHCHbQyPiL74/lhBxjGxoWbFC1Z53nmp8+23zTIJyp1G2OCOm3nbcO8TKUuGY9f08r48jnHeKGck8lnLchW7Ib8HFRFSxighu054QpahbSSJE7YSRDAHCtKa2hwZj08jZgLisvPRS1TBtmnkmQZeTTlLrHn3U7DlgsjsjZWtdnXlCqZpbbtGviytcA+JwdFhqkaLSWW1mFPeNzCgDG4McGdCo1iZJLjFL0G1GLepVcMlIFdMJ2iNCDW+8oZaNHLm5CJ18sup+zTVmL0ErRXLmFsyW+hdeMFvxg+uAS0MJBEWEUbIYcMmoQSJuxFQcgtq0uZkzZ+qKfMIAUUMsoiwg/kPVM7AEaa6uwPLDD1dNs2ebvQSdTzhB9bj1Vm0pLdl9d/Osw6BBav3EiaqzI1Ju+r37rqrI4l5fUYGUOLVWxVIpHjS2m2Ih2WVvSYYwCEbBShKLyAdcdOpAmPPF3Ki8Ve46roUbLCFECFod09xNheN+tLI+kWfp1IZXXjFb8QFLlAGBIsE4iBBg8fGgkpxbN5EhZGDESpozZ462knDpStWuECFKAwLECMQkSi4wEynz6QZ0u+IKHYSucEzwmgkTVM3NN5v/JBEix1RnBKzz3HLZ69ZFHUSIibvM5yLDFFcYCFlZc8SIEdqFI1bGQEnmltgSbbeURElcsyTYlCrzujB7wxh5mz74QC0/+miz5zS8/fdXvR5+WNU5jW3NqFHmWecCdumiBjgjYhxAhJi8y+hP7CTb7GTUwUIilsR8NwZLgvh2ik+xnyu5ki7QZBo5AUGbDWtPTVA+aDJTOywVQ4bov9122kmVO8dkaXWOF9GKOogQWUpS28TnRIQ2BysJ64jzQwiBc0RIAdeNQZW4WrEiV9OAFUQQkItGAJCpGYwmYWVjvEHsSscttHTabz+zlaBx1iyzFU0YIKhCZqSnk0U1hZ0vOD9YQ6T8KfLEhcNawnWj6h8xLzZHKPZCxAWhMve9997TF5A4EDVBYVa1tjhu4fonnzR7CSpdN130zjNbP3eu2Yoe1h3D5UCESmUKRzHAIMr5olKb9Zlo24gT8STuoWdv1OAGb8D7XCGIrRBZN4x7ieGGsTY0sSDEKCwryIIItbrM6A7bb68qXUHqDV9+abYSrHJGOxbDL7ZRLldswSIjODEhEaH2Q5umbWPls0KBvfMu9XBYSlibrA7AoMwqBsRIC9meYhes5udiptrVAVmSleKxsMXHzbKDD1YbvvjC7CnVffx4VT16tNlzXLHp09X3xx5r9pz/P/usmldVpVO7jHil7rpwjYhnMDozmpMtlJhQMHCuybLRH1i9gPZDbBQXjhBFLkv5ZkOshAgBIh2P9UCn5UQX28TC9U89pVZeconZc3COr/+sWarcs8Z008yZaoPTUav23FPPOyNdy/ISWBGY4XaZ2VKD42d0xm0g8Mo1KqZBIqrQfuytmDj/uMQMBgxquMTEnIK8DrEQIho3AkTmAOuHxu1emrWY+P4Xv1CNjmls6eqIEvVGfqDx4GbyO6mx4VFKM7iZ9MmoTKfACipVMS1FCFOwiijtBcGxq4Dyl75C0JvQRVBiFGkh4qdhdhJn4GRicpKKL9YRlrljtZ75ZP3eektVZHlLaDo0pjaNi4wJxX/FbFVwnbBSyVpizbFYWCkJaBRgEGPA5q99cF3sNv8jvhRUnC6yQkTk3wY6qQVidC32OMOKU09VDa++avaUqnZEqfu115q97KDxIMLEWRAiJk4WwtfPFkZdlvGgkSOaNPRiFs24gkwEeV0iJ0T8HGpO6IDUAuHzlkLDbvjvf9WKM84wewn6Os91yHEheM4HmRCCjwQiCc6HnRnkmBAgrhHHks096oVoEhkhwnTEn2UyJHEg2+FKhRWnndZmAmsXxzqq+fOfzV7uYCHZ+91jIeHvU4mLC1QIS5Hrg5WKAFHti/AQB+JYBKHkhYjDxwXBCnIHOUvJvE9mDfX597/bVFPnCwQJd5XpEmRFcInIiCAMuEX5spa4LlwPvoNsJZkYBgq+zyYLSukaCcFS0kJk64Fo4NwpgyBnKVlBFkQIMbKwHIh7Jn4QcNkRCUSJB6KBMCBGWEqIOdYSD85pKquJz7HBTCwergnXg8/mM3kfn4cA2c8UBC8lKUQ0eOIepKlzWaa1GKh3LJ/aX/3K7CXo869/qcpddzV7wUMT4JwiHNaKIeNG9g2BsU0kmYhYAUNwuAZYOmQmeS371soShHSUlBBxqJSeE+TE+iHOUepZluWjRqmmTz81e4WxhjLBeeaBpWO3eaSC82/FyP4VhGwoGSFi5CUQzV+WB41ClmXt5Mlq9bhxZi9BPjJlglBqFLUQcWi4BrhhFLtR3cnUjFK2gCzNCxaopfvum7ivvaHrb36jujkPQYgbRWtDY/nYZVqJWQwfPlxPWYiCCMHau+9uI0IVjpvZdcwYsycI8aLoLCLiEtSakI4n1hDGMq1B4509DzUTJ6ouJ55o9gQhXhSVEJGloeAOqIimviWKGRdvut6uRy0IcaUoXDPiQCxhwQJNCBBzw0jJR1GE6l96qY0IQfUFF5gtQYgnoQoRxhjTDlgRDjeMOFDYy7QGzYbPPzdbCbqcdprq6FmDWhDiRiiuGV9JBe7cuXO11cPkVKpv4wB356h1XLPmxYtV1V576bWGNsybp5ocMdYz71tadLyo4wEHmHckp7WpSTXNmKEXR9vgnEdWdKQeqayyUtchJXs/n7/KrG1Uc9NNGb9DEApFQYXIChDpeB6k4yn9j0omzC/1jmu2/vHHVdNHH6nmb74xz26ictgw1efFF81eW5qXLFFr//Y3tfaee8wzm0NVNtXZXpYfcYRq+vBDvV25226qz/PP621BCJuCuWak4MmEWSuIW+bihsVNhNbef7+2iOqfey6pCGlSjA31//mPWrb//mlFSJPi/Ru++spstd0WhLAJXIgIRLN8qa2Ktjd/i+PkR2qHVv/xj2YvOdx+utuVV5q9Tax/4glVO3q0al271jyTnIoBA5K+Hzofd5zZarstCGETuGuG+DBDnmJEpmXEdR7SmjvvVHU33GD2NlHuuKYdDzxQL4JfucceSZf+qHdcqNrzzjN7m6jad19VueOOqsPQoarCcXP13y22MP9NTsPrr+u/HX/6U/1XEIqBgsSI+Iq4uWBu1tx2m6qbONHsGRyLsNeUKbqGKB2ta9aopfvtp1qWLzfPJGDRNBZPE4QoUFQFjVFk3YMPqlW//73ZS1DWrZvqdf/9qmrvvc0zqUlmSfWcPFl1+vnPzV7p0/ztt2rd44+r5u++U60NDaq8a1d9U0myevwVoo8IUYC0rFypljkuUEttrXnGccX69FE977lHVf3oR+aZ1GAFLXXEqrW+3jyjVPdx41T12WebvXCgTAB3kYm7xKwqd99dVZ9+uhbYbFkzaZKqu/FGs7c5nKeuF1+sOh58sHlGiCIiRAZuWNg0e7ZqnDVLNb71lqMY5dr9yeQ6paPuppvUmttvN3vOR9bU6KkcpM79QIbNHdzmRor93njD2Qim4rzxzTfVqiuvVK0bNiT97dQ+rbvvPm2leSHW1d2x3Dofc4x5JjPe35cO6p66nHKK2ROiRuyFiFF99dVXq/okdTup6nH8QIEht452U3P99arLmWeavcywciMrOFpqHMuBSuygcN/ckaA562ZbKB2oPffcNisGJKPmlltUl5NOMnupaVm2TC11hK61rs48k5neTz2li0CF6BHPFJaB6uSVY8cmFSFNc7PZyJ71Tz5pthIgatmIkMZT4lCx9dZmKxgaTbEjUGxJlTc0vvuuLh3IJEKw6rLL1LqHHjJ7qeHW2m4RwmXt4ViPvR55RPX4y19Up6OOMv/ZhPecCtEh1kK0/rHHVOM775i9ttAxmH6hO4vpkNnQgHvngjhHtpR5Sx1yEEZgisdSx6Lg4b6R40aSGMctK1Zod81L1R57qJ733qu6X3edeWYTvH6t48Klo37aNLOVoJsjYJ1/+UtdVtDZscy6XX656vXPf5r/JmicMcNsCVEj1kLETHg3+l5iN9+sp1f0nzVLW0qLd9xRLTvkkDb3o8+II1xNzvvddBw50mxlgVeIHAvO0rp+vWpetEgHtFtWr9b72mJJ42kTs2peuFA/2PYDZQe4mW44R72feUZ1OvRQVX3WWTr47gV3t4F4VgrIlLkhlrbswAPVsoMOUoscy48Kcu5866a8Vy+zJUSNWMeIFm+3XaIDG/pNn76xIJDg9XKXe8BojeuQEed0koJevO225gnnJHfqpAakmlLB6x0BYcoFcZPKHXZQ5f366X95U/cULVbuvLOewb/hyy/Ns5tDfKfGeR/ZrI044rjIfQ/9igo10DPFZNGQIW2sLuJjyw8/3Owl6Hbpparrr39t9jaR7N5s3jiTpbWxUS0eOtTs+af7Ndeoas8dT4RoEGuLqIMn5lL/7LM6bgQEsd0Q00jlxgEdcYnT8RcNHqyW7LSToz6bCjhJv5OGZ5Rfus8++nW8hs7I6xc7ArPcsbpWnHKKWuZYTsyoB68F0Ow8zzGmEyEgvrPmrrvMXgLEzk1ZstsvecakdZ7F2rCAkokQkF73Lu7Gcax/+mmztwnvufVD17FjRYQiTKyFqONhh5mtBKuvvz4hCk6HWz1+vHl2E6udEdltQbnB1cGiAUZ8b6dunj9fL9dB0R6v0+4Ur/PA8w0vv5xYsuOyy8yzecDzXSwX4sU7PcQbdM5UyU263ytUjW+/bbY2keocumG6inb9zj1XV6ATMxKiS6yFqPPRR5uttrBmEHEULzy//MgjtaWw2f/zOIeOIr50RX6WDo5oIh7lffvqOh5cQI4Dl6jr+eebVyVo9Qbck6z/VOV25TwgMh0POsjspaaT5zXe1SiBymk33D6JmFw/R7QGONbeAMfy6/vaa4lg+NVX+/peobSJfR0RAdVVzmiLpZItZdXVqsNWW6mWNWtUy6pVqtWxZtoDAoKYkInC6qhy3DfvjRe99Jk6VVWOGGH2MkNQe8nw4WbPsX4GDVL9PFmoVBNzoeZPf1JdPDGgVHhjbwiL2wIjE7fEdSdbVgzo9957Zk+II7G2iIBlWvtOm6bvJ+a9sSFTFjoff3zKjBfTG5o++ywxR8ojQt0dNy9ZcLvHxImq/8cfqwFz5ugOOtBx2QhkYw30mDRJixB0++1vtTghGKTI2XazesIEs+UTHxZbKgsRqrJYzrbMY/F4XTHvVBCmwmRT2ChED5ni4YFOQ6cgwFzhyjLV3XyzWnPHHTr75AdKAFhpsdZxkQgwWzo41kLfl182e/5JthRIn+eeU5UuKycd/CZKESzlvXur/q4CRgv1P6Te3TBtA5H0y1LHtWQ6iKX/7NmbBd7JxjGlxsIgQEyIc65dziFDtKUkxIPYW0Reyjp31ulztwgBwdL+77+v/xIvSdZJcNU6HXaY6vXoo1qEoOtFF+m/FjJe6bJvqeh0xBGq8wknmL0EWWWfPMFp90RaN9WjR7eZRsLv6Pa735k9f1irDhCYZPU/3oXZqFWilogAPfd8Q8zIMNr1k4RoIxZRDjCrHpcM8dKPFLPPWQaE5UAsPe68M60blAysBywidywrm7jNZnVEHTqogfPmmZ3NIctHPVSHbbYxz/iHrKDOMDY26ttoV1LOkAT3GtqpwHVG2IVoIxZRDpT37KldCCyoVCKES0Q63o2f9LWFIHPdrbdqV8YbUK/MZgIoMSL33DXqitJMGanYcst2iRAQz0JsqbhOJULA4v3UB6UlJnd3iTtiEQUIlsHKiy/ebKoDqWrmsqWDUoH6F15IxKWSTDbtdtVVqmuWN2Zkjpm77KCv4/YQjwkbhJlzxLSPZm6tNGeOav76ay3wNRMm+F42RShdRIgCgk5Ve+GFeqqIm+5/+IOqHjPG7LUF4WIyaP3UqcknpRrI8OHyZEvtOedocbP0vO8+1WnUKLMnCOEhrlkAMG9spSMUXhEi+5RKhKhiZurHqksvTSlCBI4Rj/aIELDYvpsGz6RfQQgLsYjyzAbHrSCo7J0P1uXkk/Ws9VQgQnaKiBfcp2rnM3NdFM07kReoZCbQLghhIhZRniAozfrLLGPhFSHWmE4nQpCsHIDMGgvlE8vJx8qMzMZngTY33qVQBCEM4nuPnzzy3aBB31SUlbUtPDK0OIbIlgsWJJnq3pZFgwff3dLSco7eaW1dWt7c/KeBS5bcoffzyPxBg14sLyvbGBjq0NCwfb/ly9NP5xeEgBEhygMLBw3ixm1mz0Vra+OghQuLLv+8cIstJjk++S4byspuGrxggdwAXwgdEaI8kFSIysrmD5o/f7DZEwQhDRIjygOtra3uVd2/H7hgQQ8RIUEQBEEoGZT6P0lnRA3VjoonAAAAAElFTkSuQmCC"
    }
   },
   "cell_type": "markdown",
   "id": "f203ffeb-9f3c-4afb-99c2-ff7548439c2f",
   "metadata": {},
   "source": [
    "# ◇ 계층 클래스 Affine\n",
    "#### Affine클래스는 해당 부분을 저장\n",
    "![image.png](attachment:8d7f22dd-1fe5-4f25-9a13-ed54f875196f.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "416b1d0a-13ea-44e5-9bdc-a7dbcbae826b",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Affine:\n",
    "    def __init__(self, W, b):\n",
    "        self.W = W\n",
    "        self.b = b\n",
    "        \n",
    "        self.x = None\n",
    "        self.original_x_shape = None\n",
    "        # 가중치와 편향 매개변수의 미분\n",
    "        self.dW = None\n",
    "        self.db = None\n",
    "\n",
    "    def forward(self, x, flg):\n",
    "        # 텐서 대응\n",
    "        self.original_x_shape = x.shape\n",
    "        x = x.reshape(x.shape[0], -1)\n",
    "        self.x = x\n",
    "\n",
    "        #print(self.x.shape, self.W.shape)\n",
    "        out = np.dot(self.x, self.W) + self.b\n",
    "\n",
    "        return out\n",
    "\n",
    "    def backward(self, dout):\n",
    "        dx = np.dot(dout, self.W.T)\n",
    "        self.dW = np.dot(self.x.T, dout)\n",
    "        self.db = np.sum(dout, axis=0)\n",
    "        \n",
    "        dx = dx.reshape(*self.original_x_shape)  # 입력 데이터 모양 변경(텐서 대응)\n",
    "        return dx"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0f833bc6-a684-4aae-bfe6-1dc5eb1deea7",
   "metadata": {},
   "source": [
    "# ◇ 활성화 함수 Relu, softmax\n",
    "# ◇ 손실 함수 cross_entropy_error (교차 엔트로피 오차)\n",
    "# ◇ 수치미분-기울기 numerical_gradient\n",
    "# ◇ 출력층 클래스 -> 소프트맥스, 손실 함수 값을 계산-저장 SoftmaxWithLoss"
   ]
  },
  {
   "attachments": {
    "bd1cf732-a572-423f-b55b-73b2ffe87b4d.png": {
     "image/png": "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"
    }
   },
   "cell_type": "markdown",
   "id": "5b826560-ed44-4924-a0b6-505c35fdb261",
   "metadata": {},
   "source": [
    "----\n",
    "#### class Relu는 해당 부분을 저장\n",
    "![image.png](attachment:bd1cf732-a572-423f-b55b-73b2ffe87b4d.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "6f5d19d7-b9be-4a3c-bd3d-697ab7937acf",
   "metadata": {},
   "outputs": [],
   "source": [
    "def sigmoid(x):\n",
    "    return 1 / (1 + np.exp(-x))    \n",
    "\n",
    "\n",
    "def sigmoid_grad(x):\n",
    "    return (1.0 - sigmoid(x)) * sigmoid(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "900abb2e-bfb9-445b-a126-c27b6a04fc56",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Relu 활성화 함수 순전파, 역전파를 저장하는 클래스\n",
    "class Relu:\n",
    "    def __init__(self):\n",
    "        self.out = None\n",
    "\n",
    "    def forward(self, x, flg):\n",
    "        out = sigmoid(x)\n",
    "        self.out = out\n",
    "        return out\n",
    "\n",
    "    def backward(self, dout):\n",
    "        dx = dout * (1.0 - self.out) * self.out\n",
    "\n",
    "        return dx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "0269eb61-553f-439e-a374-83fc8f58d409",
   "metadata": {},
   "outputs": [],
   "source": [
    "def softmax(x):\n",
    "    if x.ndim == 2:\n",
    "        x = x.T\n",
    "        x = x - np.max(x, axis=0)\n",
    "        y = np.exp(x) / np.sum(np.exp(x), axis=0)\n",
    "        return y.T \n",
    "\n",
    "    x = x - np.max(x) # 오버플로 대책\n",
    "    return np.exp(x) / np.sum(np.exp(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "b7b8e697-02c5-4dfe-b1ae-58b68d3a9c41",
   "metadata": {},
   "outputs": [],
   "source": [
    "def cross_entropy_error(y, t):\n",
    "    if y.ndim == 1:\n",
    "        t = t.reshape(1, t.size)\n",
    "        y = y.reshape(1, y.size)\n",
    "        \n",
    "    if t.size == y.size:\n",
    "        t = t.argmax(axis=1)\n",
    "             \n",
    "    batch_size = y.shape[0]\n",
    "    return -np.sum(np.log(y[np.arange(batch_size), t] + 1e-7)) / batch_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "03e460e1-bfc6-4a06-818b-02c9051cf088",
   "metadata": {},
   "outputs": [],
   "source": [
    "def numerical_gradient(f, x):\n",
    "    h = 1e-4 # 0.0001\n",
    "    grad = np.zeros_like(x)\n",
    "    \n",
    "    it = np.nditer(x, flags=['multi_index'], op_flags=['readwrite'])\n",
    "    while not it.finished:\n",
    "        idx = it.multi_index\n",
    "        tmp_val = x[idx]\n",
    "        x[idx] = float(tmp_val) + h\n",
    "        fxh1 = f(x) # f(x+h)\n",
    "        \n",
    "        x[idx] = tmp_val - h \n",
    "        fxh2 = f(x) # f(x-h)\n",
    "        grad[idx] = (fxh1 - fxh2) / (2*h)\n",
    "        \n",
    "        x[idx] = tmp_val # 값 복원\n",
    "        it.iternext()   \n",
    "        \n",
    "    return grad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "161c7d2d-c4cc-4ce3-89c3-5ceac9417267",
   "metadata": {},
   "outputs": [],
   "source": [
    "class SoftmaxWithLoss:\n",
    "    def __init__(self):\n",
    "        self.loss = None # 손실함수\n",
    "        self.y = None    # softmax의 출력\n",
    "        self.t = None    # 정답 레이블(원-핫 인코딩 형태)\n",
    "        \n",
    "    def forward(self, x, t):\n",
    "        self.t = t\n",
    "        self.y = softmax(x)\n",
    "        self.loss = cross_entropy_error(self.y, self.t)\n",
    "        \n",
    "        return self.loss\n",
    "\n",
    "    def backward(self, dout=1):\n",
    "        batch_size = self.t.shape[0]\n",
    "        if self.t.size == self.y.size: # 정답 레이블이 원-핫 인코딩 형태일 때\n",
    "            dx = (self.y - self.t) / batch_size\n",
    "        else:\n",
    "            dx = self.y.copy()\n",
    "            dx[np.arange(batch_size), self.t] -= 1\n",
    "            dx = dx / batch_size\n",
    "        \n",
    "        return dx"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2537370a-1915-42f0-9c91-f5cc11998fc8",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "# ◇ 최적화 함수 SGD, Momentum, AdaGrad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "30cb3c94-71ab-480f-ad5c-911166b74ffc",
   "metadata": {},
   "outputs": [],
   "source": [
    "class SGD:\n",
    "    def __init__(self, Ir=0.01):\n",
    "        self.Ir =Ir\n",
    "\n",
    "    def update(self, params, grads):\n",
    "        for key in params.keys():\n",
    "            params[key] -= self.Ir * grads[key]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "0f0c4a9c-4131-4946-962d-154d22eddf8b",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Momentum:\n",
    "    def __init__(self, lr=0.01, momentum=0.9):\n",
    "        self.lr = lr\n",
    "        self.momentum = momentum\n",
    "        self.v = None\n",
    "\n",
    "    def update(self, params, grads):\n",
    "        if self.v is None:\n",
    "            self.v = {}\n",
    "            for key, val in params.items():\n",
    "                self.v[key] = np.zeros_like(val)\n",
    "\n",
    "        for key in params.keys():\n",
    "            self.v[key] = self.momentum * self.v[key] - self.lr * grads[key]\n",
    "            params[key] += self.v[key]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "df7ccc05-fa98-4a9a-8e0a-adf50ac4d2d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "class AdaGrad:\n",
    "    def __init__ (self, Ir=0.01):\n",
    "        self.Ir =Ir\n",
    "        self.h = None\n",
    "        \n",
    "    def update(self, params, grads):\n",
    "        if self.h is None:\n",
    "            self.h = {}\n",
    "            for key, val in params.items():\n",
    "                self.h[key] = np.zeros_like(val)\n",
    "\n",
    "        for key in params.keys() :\n",
    "            self.h[key] += grads[key] * grads[key]\n",
    "            params[key] -= self.Ir * grads[key] / (np.sqrt(self.h[key]) + 1e-7)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "705ad2f6-185b-4724-a432-2e4638118105",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "# ◇ 학습 자료에 있는 배치 정규화 코드"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "e592201f-c9dc-49a6-a6d9-3f52dad159bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "class BatchNormalization:\n",
    "    \"\"\"\n",
    "    http://arxiv.org/abs/1502.03167\n",
    "    \"\"\"\n",
    "    def __init__(self, gamma=1, beta=0, momentum=0.9, running_mean=None, running_var=None):\n",
    "        self.gamma = gamma\n",
    "        self.beta = beta\n",
    "        self.momentum = momentum\n",
    "        self.input_shape = None # 합성곱 계층은 4차원, 완전연결 계층은 2차원  \n",
    "\n",
    "        # 시험할 때 사용할 평균과 분산\n",
    "        self.running_mean = running_mean\n",
    "        self.running_var = running_var  \n",
    "        \n",
    "        # backward 시에 사용할 중간 데이터\n",
    "        self.batch_size = None\n",
    "        self.xc = None\n",
    "        self.std = None\n",
    "        self.dgamma = None\n",
    "        self.dbeta = None\n",
    "\n",
    "    def forward(self, x, train_flg=True):\n",
    "        self.input_shape = x.shape\n",
    "        if x.ndim != 2:\n",
    "            N, C, H, W = x.shape\n",
    "            x = x.reshape(N, -1)\n",
    "\n",
    "        out = self.__forward(x, train_flg)\n",
    "        \n",
    "        return out.reshape(*self.input_shape)\n",
    "            \n",
    "    def __forward(self, x, train_flg):\n",
    "        if self.running_mean is None:\n",
    "            N, D = x.shape\n",
    "            self.running_mean = np.zeros(D)\n",
    "            self.running_var = np.zeros(D)\n",
    "                        \n",
    "        if train_flg:\n",
    "            mu = x.mean(axis=0)\n",
    "            xc = x - mu\n",
    "            var = np.mean(xc**2, axis=0)\n",
    "            std = np.sqrt(var + 10e-7)\n",
    "            xn = xc / std\n",
    "            \n",
    "            self.batch_size = x.shape[0]\n",
    "            self.xc = xc\n",
    "            self.xn = xn\n",
    "            self.std = std\n",
    "            self.running_mean = self.momentum * self.running_mean + (1-self.momentum) * mu\n",
    "            self.running_var = self.momentum * self.running_var + (1-self.momentum) * var            \n",
    "        else:\n",
    "            xc = x - self.running_mean\n",
    "            xn = xc / ((np.sqrt(self.running_var + 10e-7)))\n",
    "            \n",
    "        out = self.gamma * xn + self.beta \n",
    "        return out\n",
    "\n",
    "    def backward(self, dout):\n",
    "        if dout.ndim != 2:\n",
    "            N, C, H, W = dout.shape\n",
    "            dout = dout.reshape(N, -1)\n",
    "\n",
    "        dx = self.__backward(dout)\n",
    "\n",
    "        dx = dx.reshape(*self.input_shape)\n",
    "        return dx\n",
    "\n",
    "    def __backward(self, dout):\n",
    "        dbeta = dout.sum(axis=0)\n",
    "        dgamma = np.sum(self.xn * dout, axis=0)\n",
    "        dxn = self.gamma * dout\n",
    "        dxc = dxn / self.std\n",
    "        dstd = -np.sum((dxn * self.xc) / (self.std * self.std), axis=0)\n",
    "        dvar = 0.5 * dstd / self.std\n",
    "        dxc += (2.0 / self.batch_size) * self.xc * dvar\n",
    "        dmu = np.sum(dxc, axis=0)\n",
    "        dx = dxc - dmu / self.batch_size\n",
    "        \n",
    "        self.dgamma = dgamma\n",
    "        self.dbeta = dbeta\n",
    "        \n",
    "        return dx"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e8d61b57-e961-4aba-907a-a7363c23a617",
   "metadata": {},
   "source": [
    "# ◇ 가중치 초기화 He"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "6e97a344-d757-4dfd-8c54-74d3316db214",
   "metadata": {},
   "outputs": [],
   "source": [
    "def He_init(input, ouput):\n",
    "    return np.sqrt(1.0 / input) * np.random.randn(input, ouput)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ebca134e-acc5-4564-8087-4359506948b9",
   "metadata": {},
   "source": [
    "# ◇ 다층 신경망 클래스"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "efbc06eb-3fe1-40fb-9bde-7398eda3a619",
   "metadata": {},
   "outputs": [],
   "source": [
    "class TwoLayerNet:\n",
    "\n",
    "    def __init__(self, input_size, hidden_size, output_size, weight_init_std = 0.01):\n",
    "        # 가중치 초기화\n",
    "        self.maxIndex = len(hidden_size)\n",
    "        print(\"\\n\\n신경망 학습 시작 - 신경망: %d층\"%(self.maxIndex+1))\n",
    "        \n",
    "        self.params = {}        \n",
    "        self.params['W1'] = He_init(input_size, hidden_size[0])\n",
    "        self.params['b1'] = np.zeros(hidden_size[0])\n",
    "\n",
    "        #print(self.params['W1'].shape)\n",
    "\n",
    "        for i in range(1, self.maxIndex):\n",
    "            self.params['W' + str(i+1)] = He_init(hidden_size[i-1], hidden_size[i]) \n",
    "            self.params['b' + str(i+1)] = np.zeros(hidden_size[i])\n",
    "            #print(self.params['W'  + str(i+1)].shape)\n",
    "\n",
    "        self.params['W' + str(self.maxIndex)] = He_init(hidden_size[self.maxIndex - 1], output_size) \n",
    "        self.params['b' + str(self.maxIndex)] = np.zeros(output_size)\n",
    "        #print(self.params['W' + str(self.maxIndex)].shape)\n",
    "\n",
    "        # 계층 생성\n",
    "        self.layers = OrderedDict()\n",
    "        \n",
    "        for i in range(1, self.maxIndex):\n",
    "            self.layers['Affine' + str(i)] = Affine(self.params['W' + str(i)], self.params['b' + str(i)])\n",
    "            self.layers['BatchNormalization' + str(i)] = BatchNormalization()\n",
    "            self.layers['Relu' + str(i)] = Relu()\n",
    "    \n",
    "        self.layers['Affine' + str(self.maxIndex)] = Affine(self.params['W' + str(self.maxIndex)], self.params['b' + str(self.maxIndex)])\n",
    "\n",
    "        self.lastLayer = SoftmaxWithLoss()\n",
    "        \n",
    "    def predict(self, x, train_flg=True):\n",
    "        for layer in self.layers.values():\n",
    "            x = layer.forward(x, train_flg)\n",
    "        return x\n",
    "        \n",
    "    def loss(self, x, t):\n",
    "        y = self.predict(x)\n",
    "        return self.lastLayer.forward(y, t)\n",
    "    \n",
    "    def accuracy(self, x, t):\n",
    "        y = self.predict(x, False)\n",
    "        y = np.argmax(y, axis=1)\n",
    "        if t.ndim != 1 : t = np.argmax(t, axis=1)\n",
    "        accuracy = np.sum(y == t) / float(x.shape[0])\n",
    "        return accuracy\n",
    "        \n",
    "    # x : 입력 데이터, t : 정답 레이블\n",
    "    def numerical_gradient(self, x, t):\n",
    "        loss_W = lambda W: self.loss(x, t)\n",
    "        \n",
    "        grads = {}\n",
    "\n",
    "        for i in range(1, self.maxIndex+1):\n",
    "            grads['W' + str(i)] = numerical_gradient(loss_W, self.params['W' + str(i)])\n",
    "            grads['b' + str(i)] = numerical_gradient(loss_W, self.params['b' + str(i)])\n",
    "\n",
    "        return grads\n",
    "        \n",
    "    def gradient(self, x, t):\n",
    "        # forward\n",
    "        self.loss(x, t)\n",
    "\n",
    "        # 역전파\n",
    "        dout = 1\n",
    "        dout = self.lastLayer.backward(dout)\n",
    "\n",
    "        # 계층 레이어의 값을 리스트로 변환하여 가져옴 -> 해당 리스트를 거꾸로 정렬 -> 순서대로 계층의 역전파를 실행\n",
    "        layers = list(self.layers.values())\n",
    "        layers.reverse()\n",
    "        for layer in layers:\n",
    "            dout = layer.backward(dout)\n",
    "\n",
    "        # 기울기\n",
    "        grads = {}\n",
    "        for i in range(1, self.maxIndex+1):\n",
    "            grads['W' + str(i)], grads['b' + str(i)] = self.layers['Affine' + str(i)].dW, self.layers['Affine' + str(i)].db\n",
    "        \n",
    "        return grads\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fe045263-ea41-4b2d-9b4e-e6355b8731bf",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "# ◇ MNIST 불러오기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "bac8b5d5-172c-4d85-b11a-47e141c19710",
   "metadata": {},
   "outputs": [],
   "source": [
    "(x_train, t_train), (x_test, t_test) = load_mnist(normalize=True, one_hot_label=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c2faaf13-6d43-40cc-aad4-118070e02d56",
   "metadata": {},
   "source": [
    "----\n",
    "# 과제) 신경망 학습 코드 작성 시 발생한 문제와 해결 내용\n",
    "<br/>\n",
    "\n",
    "### 1) 기존 가중치 업데이트 방식 가중치 - (학습률*기울기) / 해당 방법으로 업데이트 시 학습이 잘 안됨\n",
    "#### &emsp;&emsp;&emsp;--> 해결방법 : SGD, 모멘텀, AdaGrad를 사용해서 적절한 기울기 업데이트 방법을 사용하니 학습이 잘되는 것을 확인\n",
    "<br/>\n",
    "\n",
    "### 2) 2층 신경망에서는 학습에 문제가 없었으나 4층으로 늘릴 시 학습이 안되는 문제가 발생\n",
    "#### &emsp;&emsp;&emsp;--> 해결방법 : 초기화 방법을 변경 / ReLu함수의 가중치 초기화를  He초기화(He_init 함수)로 하니 정상적으로 학습이 가능함\n",
    "#### &emsp;&emsp;&emsp;&emsp;&emsp; 이후 층을 늘려도 학습이 되는 것을 확인\n",
    "<br/>\n",
    "\n",
    "### 3) 초기값, 모멘텀, SGD 등을 통해 어느정도 학습은 가능하나 일정 수준 이상으로 학습이 되지 않음\n",
    "#### &emsp;&emsp;&emsp;--> 해결방법 : 교제에 나온 배치치 정규화를 시도\n",
    "<br/>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b34859dd-c506-48e6-aea8-c0e96a414333",
   "metadata": {},
   "source": [
    "\n",
    "# ◇ 학습 알고리즘 \n",
    "<br />\n",
    "\n",
    "## 계산 과정\n",
    "1. TwoLayerNet클래스로 가중치 초기화 밑 신경망 구조를 설정 (hidden_size을 리스트로 보내어 좀 더 간단하게 층과 노드를 설정)\n",
    "2. 횟수는 1만번 진행하며, 하이퍼피라미터를 수정\n",
    "3. 배치 사이즈만큼 학습, 시험 데이터를 TwoLayerNet.gradient 으로 보내어 기울기를 구한다\n",
    "- - 1. loss함수에서 predict함수를 호출하여 순전파를 진행한다 (OrderedDict으로 순서가 있는 딕셔너리를 통해 입력층부터 계산)\n",
    "    2. predict함수는 출력층 전까지 값을 리턴한 후 loss함수에서 SoftmaxWithLoss클래스에 소프트맥스값, 교차 엔트로피 오차(손실)값을 설정한다.\n",
    "    3. 2번에서 설정한 SoftmaxWithLoss클래스를 역전파를 하고, OrderedDict를 리스트로 변환하여 거꾸로 정렬, 순서대로 Affine, ReLu클래스의 역전파를 실행\n",
    "    4. 역전파를 통해 각 Affine클래스에 저장된 dw, db값을 grads에 저장한 후 리턴\n",
    "4. 구한 기울기를 SGD, Momentum, AdaGrad 중 1개를 이용하여 기존 기울기에 업데이트를 진행\n",
    "\n",
    "## 하이퍼피라미터\n",
    "- #### iters_num : 반복 횟수 = **10,000 고정**\n",
    "- #### batch_size : 배치 사이즈 = **100~300?**\n",
    "- #### hidden_size : 은닉층 노드 수 = **5 ~ 15**\n",
    "- #### learning_rate : 학습률 = **0.001 ~ 0.019**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "a4eb85f2-7534-48d2-a079-75bf36710c6d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "신경망 학습 시작 - 신경망: 6층\n",
      " 1 번째 학습(에폭) --> train_acc : 16.50%, test_acc : 16.50%\n",
      " 2 번째 학습(에폭) --> train_acc : 85.12%, test_acc : 85.66%\n",
      " 3 번째 학습(에폭) --> train_acc : 87.19%, test_acc : 87.46%\n",
      " 4 번째 학습(에폭) --> train_acc : 88.41%, test_acc : 88.11%\n",
      " 5 번째 학습(에폭) --> train_acc : 88.76%, test_acc : 88.64%\n",
      " 6 번째 학습(에폭) --> train_acc : 89.10%, test_acc : 88.82%\n",
      " 7 번째 학습(에폭) --> train_acc : 89.52%, test_acc : 89.06%\n",
      " 8 번째 학습(에폭) --> train_acc : 89.91%, test_acc : 89.46%\n",
      " 9 번째 학습(에폭) --> train_acc : 90.01%, test_acc : 89.63%\n",
      "10 번째 학습(에폭) --> train_acc : 90.13%, test_acc : 89.69%\n",
      "11 번째 학습(에폭) --> train_acc : 90.49%, test_acc : 90.02%\n",
      "12 번째 학습(에폭) --> train_acc : 90.65%, test_acc : 89.98%\n",
      "13 번째 학습(에폭) --> train_acc : 90.73%, test_acc : 90.30%\n",
      "14 번째 학습(에폭) --> train_acc : 90.95%, test_acc : 90.36%\n",
      "15 번째 학습(에폭) --> train_acc : 90.98%, test_acc : 90.29%\n",
      "16 번째 학습(에폭) --> train_acc : 91.06%, test_acc : 90.62%\n",
      "17 번째 학습(에폭) --> train_acc : 91.33%, test_acc : 90.56%\n",
      "18 번째 학습(에폭) --> train_acc : 91.40%, test_acc : 90.78%\n",
      "19 번째 학습(에폭) --> train_acc : 91.40%, test_acc : 90.69%\n",
      "20 번째 학습(에폭) --> train_acc : 91.32%, test_acc : 90.72%\n",
      "21 번째 학습(에폭) --> train_acc : 91.60%, test_acc : 90.89%\n",
      "22 번째 학습(에폭) --> train_acc : 91.51%, test_acc : 91.04%\n",
      "23 번째 학습(에폭) --> train_acc : 91.60%, test_acc : 90.99%\n",
      "24 번째 학습(에폭) --> train_acc : 91.72%, test_acc : 91.01%\n",
      "25 번째 학습(에폭) --> train_acc : 91.77%, test_acc : 91.24%\n",
      "26 번째 학습(에폭) --> train_acc : 91.97%, test_acc : 91.17%\n",
      "27 번째 학습(에폭) --> train_acc : 91.93%, test_acc : 91.16%\n",
      "28 번째 학습(에폭) --> train_acc : 91.96%, test_acc : 91.10%\n",
      "29 번째 학습(에폭) --> train_acc : 92.19%, test_acc : 91.28%\n",
      "30 번째 학습(에폭) --> train_acc : 92.10%, test_acc : 91.39%\n",
      "31 번째 학습(에폭) --> train_acc : 92.22%, test_acc : 91.43%\n",
      "32 번째 학습(에폭) --> train_acc : 92.20%, test_acc : 91.41%\n",
      "33 번째 학습(에폭) --> train_acc : 92.20%, test_acc : 91.43%\n",
      "34 번째 학습(에폭) --> train_acc : 92.31%, test_acc : 91.46%\n",
      "35 번째 학습(에폭) --> train_acc : 92.38%, test_acc : 91.58%\n",
      "36 번째 학습(에폭) --> train_acc : 92.49%, test_acc : 91.59%\n",
      "37 번째 학습(에폭) --> train_acc : 92.58%, test_acc : 91.66%\n",
      "38 번째 학습(에폭) --> train_acc : 92.58%, test_acc : 91.69%\n",
      "39 번째 학습(에폭) --> train_acc : 92.48%, test_acc : 91.69%\n",
      "40 번째 학습(에폭) --> train_acc : 92.59%, test_acc : 91.84%\n",
      "41 번째 학습(에폭) --> train_acc : 92.70%, test_acc : 91.97%\n",
      "42 번째 학습(에폭) --> train_acc : 92.68%, test_acc : 91.86%\n",
      "43 번째 학습(에폭) --> train_acc : 92.70%, test_acc : 91.74%\n",
      "44 번째 학습(에폭) --> train_acc : 92.73%, test_acc : 91.80%\n",
      "45 번째 학습(에폭) --> train_acc : 92.89%, test_acc : 92.07%\n",
      "46 번째 학습(에폭) --> train_acc : 92.77%, test_acc : 91.92%\n",
      "47 번째 학습(에폭) --> train_acc : 92.86%, test_acc : 91.99%\n",
      "48 번째 학습(에폭) --> train_acc : 92.90%, test_acc : 92.00%\n",
      "49 번째 학습(에폭) --> train_acc : 92.93%, test_acc : 92.12%\n",
      "50 번째 학습(에폭) --> train_acc : 92.92%, test_acc : 91.96%\n",
      "최종 학습률 --> train_acc : 92.92%, test_acc : 91.96%\n"
     ]
    }
   ],
   "source": [
    "# 100, [15, 15, 15], 0.011\n",
    "\n",
    "# 287, [15, 15, 15, 15, 15], 0.015\n",
    "\n",
    "\n",
    "iters_num = 10000\n",
    "batch_size = 300\n",
    "#hidden_size = 15 \n",
    "hidden_size = [15, 15, 15, 15, 15]\n",
    "learning_rate = 0.015\n",
    "\n",
    "# 기울기 최적화 함수들\n",
    "sgd = SGD()\n",
    "momentum = Momentum()\n",
    "adaGrad = AdaGrad()\n",
    "\n",
    "train_loss_list = []\n",
    "train_acc_list = []\n",
    "test_acc_list = []\n",
    "\n",
    "train_size = x_train.shape[0]\n",
    "iter_per_epoch = max(train_size / batch_size, 1)\n",
    "\n",
    "network = TwoLayerNet(input_size=784, hidden_size=hidden_size, output_size=10)\n",
    "\n",
    "for i in range(iters_num):\n",
    "    batch_mask = np.random.choice(train_size, batch_size)\n",
    "    x_batch = x_train[batch_mask]\n",
    "    t_batch = t_train[batch_mask]\n",
    "\n",
    "    grad = network.gradient(x_batch, t_batch) # 오차역전파법 방식\n",
    "    \n",
    "    # 일반 갱신\n",
    "    #for key in ('W1', 'b1', 'W2', 'b2'): network.params[key] -= learning_rate * grad[key]\n",
    "        \n",
    "    # SGD 학습, 모멘텀 학습, AdaGrad 학습\n",
    "    #sgd.update(network.params, grad)\n",
    "    #momentum.update(network.params, grad)\n",
    "    adaGrad.update(network.params, grad)\n",
    "    \n",
    "    \n",
    "    loss = network.loss(x_batch, t_batch)\n",
    "    train_loss_list.append(loss)\n",
    "    \n",
    "    if i % iter_per_epoch == 0:\n",
    "        train_acc = network.accuracy(x_train, t_train)\n",
    "        test_acc = network.accuracy(x_test, t_test)\n",
    "        train_acc_list.append(train_acc)\n",
    "        test_acc_list.append(test_acc)\n",
    "        print(\"%2d 번째 학습(에폭) --> train_acc : %.2f%%, test_acc : %.2f%%\" % (len(train_acc_list), train_acc*100, test_acc*100))\n",
    "        \n",
    "print(\"최종 학습률 --> train_acc : %.2f%%, test_acc : %.2f%%\" % (train_acc_list[-1]*100, test_acc_list[-1]*100))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0f70fef2-d5d5-4457-93bc-9025cb52b372",
   "metadata": {},
   "source": [
    "----"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "f0b8f9d4-e24e-49cb-ae62-c4bc3c82de3e",
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "'return' outside function (724303023.py, line 1)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;36m  Cell \u001b[1;32mIn[49], line 1\u001b[1;36m\u001b[0m\n\u001b[1;33m    return\u001b[0m\n\u001b[1;37m    ^\u001b[0m\n\u001b[1;31mSyntaxError\u001b[0m\u001b[1;31m:\u001b[0m 'return' outside function\n"
     ]
    }
   ],
   "source": [
    "return\n",
    "\n",
    "import optuna\n",
    "import numpy as np\n",
    "\n",
    "# 기울기 최적화 함수들\n",
    "\n",
    "# 하이퍼파라미터 범위 설정\n",
    "learning_rate_range = [0.001, 0.019]\n",
    "num_layers_range = (3, 6)\n",
    "iters_num_range = (10000, 10000)  # Fixed iterations (can be removed for further tuning)\n",
    "batch_size_range = (100, 300)\n",
    "\n",
    "def objective(trial):\n",
    "    # 하이퍼파라미터 설정\n",
    "    learning_rate = trial.suggest_float(\"learning_rate\", learning_rate_range[0], learning_rate_range[1])\n",
    "    #hidden_size = [trial.suggest_int(\"hidden_size_{}\".format(i), hidden_size_range[i][0], hidden_size_range[i][1]) for i in range(len(hidden_size_range))]\n",
    "    num_layers = trial.suggest_int(\"num_layers\", num_layers_range[0], num_layers_range[1])\n",
    "    hidden_size = [15] * num_layers\n",
    "    iters_num = trial.suggest_int(\"iters_num\", iters_num_range[0], iters_num_range[1])\n",
    "    batch_size = trial.suggest_int(\"batch_size\", batch_size_range[0], batch_size_range[1])\n",
    "\n",
    "    # 모델 생성\n",
    "    network = TwoLayerNet(input_size=784, hidden_size=hidden_size, output_size=10)\n",
    "\n",
    "    # 최적화 알고리즘 설정\n",
    "    #optimizer = Momentum()  # SGD, Momentum, AdaGrad 등 사용 가능\n",
    "    sgd = SGD()\n",
    "    momentum = Momentum()\n",
    "    adaGrad = AdaGrad()\n",
    "\n",
    "    \n",
    "    # 학습 및 평가\n",
    "    train_loss_list = []\n",
    "    train_acc_list = []\n",
    "    test_acc_list = []\n",
    "\n",
    "    train_size = x_train.shape[0]\n",
    "    iter_per_epoch = max(train_size // batch_size, 1)\n",
    "\n",
    "    print(\"learning_rate:\", learning_rate)\n",
    "    print(\"hidden_size:\", hidden_size)\n",
    "    #print(\"iters_num:\", iters_num)\n",
    "    print(\"batch_size:\", batch_size)\n",
    "    \n",
    "    for i in range(iters_num):\n",
    "        # 배치 데이터 추출\n",
    "        batch_mask = np.random.choice(train_size, batch_size)\n",
    "        x_batch = x_train[batch_mask]\n",
    "        t_batch = t_train[batch_mask]\n",
    "\n",
    "        # 오차역전파법으로 기울기 계산\n",
    "        grad = network.gradient(x_batch, t_batch)\n",
    "\n",
    "        # SGD 학습, 모멘텀 학습, AdaGrad 학습\n",
    "        #sgd.update(network.params, grad)\n",
    "        #momentum.update(network.params, grad)\n",
    "        adaGrad.update(network.params, grad)\n",
    "\n",
    "        # 손실 계산\n",
    "        loss = network.loss(x_batch, t_batch)\n",
    "        train_loss_list.append(loss)\n",
    "\n",
    "        # 에포크 마다 평가\n",
    "        if i % iter_per_epoch == 0:\n",
    "            train_acc = network.accuracy(x_train, t_train)\n",
    "            test_acc = network.accuracy(x_test, t_test)\n",
    "            train_acc_list.append(train_acc)\n",
    "            test_acc_list.append(test_acc)\n",
    "            #print(\"%2d 번째 학습(에폭) --> train_acc : %.2f%%, test_acc : %.2f%%\" % (len(train_acc_list), train_acc*100, test_acc*100))\n",
    "    print(\"(에폭) --> train_acc : %.2f%%, test_acc : %.2f%%\" % (train_acc_list[-1]*100, test_acc_list[-1]*100))\n",
    "    # 테스트 정확도 반환\n",
    "    \n",
    "    return test_acc_list[-1]  # 마지막 에포크의 테스트 정확도 사용\n",
    "\n",
    "\n",
    "study = optuna.create_study(direction=\"maximize\")\n",
    "study.optimize(objective, n_trials=100)  # 100번의 튜닝 수행\n",
    "\n",
    "best_params = study.best_params\n",
    "print(\"최적의 하이퍼파라미터:\")\n",
    "print(\"learning_rate:\", best_params[\"learning_rate\"])\n",
    "print(\"hidden_size:\", best_params[\"num_layers\"])\n",
    "print(\"최고의 테스트 정확도:\", study.best_value)\n"
   ]
  },
  {
   "cell_type": "raw",
   "id": "ac5fa1b5-7f89-489d-a9a1-284989870f4e",
   "metadata": {},
   "source": [
    "learning_rate: 0.010963056767964934\n",
    "iters_num: 4\n",
    "최고의 테스트 정확도: 0.9536"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d995a78f-7dfe-45da-8191-272f4320de8c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "98fcfaad-c560-4179-824c-0ed1d3fc43f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import tensorflow as tf \n",
    "from tensorflow.python.client import device_lib\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"0\"\n",
    "\n",
    "print(device_lib.list_local_devices() )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "063a9e11-fdfd-4db5-855b-f2a0b879f7ef",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ff54f8b-4e11-48b4-9620-94b5d1a74ae5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd19b0ce-7b61-4de0-b6ed-e86c5692856a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c0d9b968-c02c-40eb-b72b-1335e09a0f6a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd912137-5af2-4565-9eb2-ef5dcc1917ed",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e68d64b-6fbe-4dd4-9010-74a2499f5505",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1162bddb-0828-45fd-9529-6832eef0fe5e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d3fd7a9-860f-42c4-80f6-18d0a0b84d80",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d9791f8-3241-48bd-a23f-1eed887c4530",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65c9ef26-b09d-4982-a7a9-8fd7cf5910c8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9fa2413d-7467-4e74-9d48-7ca28020079e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "109311be-25cf-4059-b1e9-18594285bf38",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "482fd3ff-9243-4a64-9001-2a3a61da2d2b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc65e910-0666-44eb-99dc-bb73635a984f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b671a238-daf6-4c61-aba4-7cca58294abf",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad4104d2-5a75-4c5e-a556-6f13a5f3d362",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
